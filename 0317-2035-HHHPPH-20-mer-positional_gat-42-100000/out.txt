seq =  HHHPPHPHPHPPHPHPHPPH
seed =  42
algo =  positional_gat
save_path =  ./0317-2035-HHHPPH-20-mer-positional_gat-42-100000/
num_episodes =  100000
##### Summary of Hyperparameters #####
learning_rate:  0.0005
BATCH_SIZE:  32
GAMMA:  0.98
mem_start_train:  1000
TARGET_UPDATE:  100
buffer_limit:  10000
train_times:  10
##### End of Summary of Hyperparameters #####
decay_mode=exponential warmRestart=True
num_restarts=1 exploration_decay_rate=5 start_decay=0
initial state/obs:
((array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]), array([0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0])), {'state': [(0, 0), (0, 1)]})
n_actions =  3
TransformerModel with:
inputs_size=4 hidden_size=128 num_layers=2 num_classes=3
found new highest reward =  1.0
{'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 2, 0, 0, 1, 2, 0, 2, 0, 1, 0, 0, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-3, 1), (-3, 0), (-3, -1), (-4, -1), (-4, -2), (-5, -2), (-5, -3), (-5, -4), (-4, -4), (-4, -3), (-3, -3), (-3, -2), (-2, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 0, score: 1.0, epsilon: 1.00, reward_max: 1.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 2, 0, 0, 1, 2, 0, 2, 0, 1, 0, 0, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-3, 1), (-3, 0), (-3, -1), (-4, -1), (-4, -2), (-5, -2), (-5, -3), (-5, -4), (-4, -4), (-4, -3), (-3, -3), (-3, -2), (-2, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
found new highest reward =  2.0
{'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 1, 2, 0, 0, 2, 2, 1, 1, 2, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-2, -4), (-2, -5), (-1, -5), (-1, -6), (-2, -6), (-3, -6), (-4, -6), (-4, -5), (-4, -4), (-5, -4), (-5, -5), (-5, -6)], 'first_turn_left': True, 'is_trapped': False}
found new highest reward =  3.0
{'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 2, 0, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, 0), (-3, 0), (-4, 0), (-5, 0), (-5, -1), (-4, -1), (-3, -1), (-3, -2), (-2, -2), (-2, -3), (-3, -3), (-4, -3), (-4, -2), (-5, -2)], 'first_turn_left': True, 'is_trapped': False}
found new highest reward =  4.0
{'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 0, 2, 1, 2, 2, 0, 0, 1, 0, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, -2), (-3, -3), (-2, -3), (-1, -3), (-1, -4), (0, -4), (0, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 99, score: 2.0, epsilon: 1.00, reward_max: 4.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 199, score: 1.0, epsilon: 0.99, reward_max: 4.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 2, 0, 2, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-3, 1), (-3, 0), (-3, -1), (-3, -2), (-2, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-3, -4), (-4, -4), (-4, -3), (-4, -2), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
found new highest reward =  5.0
{'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 2, 2, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -4), (0, -5), (1, -5), (1, -4), (1, -3), (1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 299, score: 3.0, epsilon: 0.99, reward_max: 5.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 0, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-4, -1), (-4, -2), (-4, -3), (-5, -3), (-5, -4), (-4, -4), (-3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 399, score: 2.0, epsilon: 0.98, reward_max: 5.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 1, 1, 1, 0, 0, 1, 1, 2, 2, 0, 1, 2, 2, 1, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-4, 1), (-3, 1), (-2, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-2, -2), (-3, -2), (-3, -1), (-3, 0), (-4, 0), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 499, score: 2.0, epsilon: 0.98, reward_max: 5.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-4, -1), (-4, 0), (-4, 1), (-5, 1), (-5, 0), (-5, -1), (-6, -1), (-6, 0), (-7, 0), (-8, 0), (-8, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 599, score: 0.0, epsilon: 0.97, reward_max: 5.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 2, 1, 1, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-2, 3), (-2, 4), (-2, 5), (-1, 5), (0, 5), (0, 4), (0, 3), (1, 3), (2, 3), (2, 2), (2, 1), (2, 0), (2, -1), (3, -1), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
found new highest reward =  7.0
{'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 0, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0, 1, 1, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -1), (-3, 0), (-2, 0), (-2, 1), (-2, 2), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 699, score: 1.0, epsilon: 0.97, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (0, 4), (0, 5), (1, 5), (2, 5), (2, 4), (3, 4), (3, 5), (3, 6), (2, 6), (2, 7), (2, 8), (1, 8)], 'first_turn_left': True, 'is_trapped': False}
Episode 799, score: 2.0, epsilon: 0.96, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 2, 2, 1, 2, 0, 1, 0, 0, 2, 0, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-3, -1), (-3, 0), (-3, 1), (-2, 1), (-2, 2), (-2, 3), (-3, 3), (-3, 2), (-4, 2), (-4, 1), (-4, 0), (-4, -1), (-4, -2), (-4, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 899, score: 6.0, epsilon: 0.96, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (1, -3), (2, -3), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 999, score: 1.0, epsilon: 0.95, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 2, 0, 1, 0, 2, 2, 0, 1, 1, 2, 2, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-2, -2), (-2, -3), (-2, -4), (-1, -4), (-1, -5), (-2, -5), (-2, -6), (-2, -7), (-2, -8), (-3, -8), (-3, -7), (-3, -6), (-4, -6), (-4, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 1099, score: 0.0, epsilon: 0.95, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 0, 2, 0, 0, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-5, 0), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (2, -1), (3, -1), (4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 1199, score: 1.0, epsilon: 0.94, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 2, 0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-2, -5), (-1, -5), (-1, -4), (0, -4), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 1299, score: 0.0, epsilon: 0.94, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 2, 2, 0, 0, 1, 2, 2, 0, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-2, -3), (-2, -2), (-3, -2), (-3, -3), (-3, -4), (-4, -4), (-4, -3), (-5, -3), (-6, -3), (-6, -4), (-6, -5), (-6, -6), (-6, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 1399, score: 1.0, epsilon: 0.93, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 2, 0, 2, 2, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3), (2, 2), (3, 2), (3, 3), (3, 4), (3, 5), (4, 5), (5, 5), (6, 5), (6, 6), (6, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 1499, score: 1.0, epsilon: 0.93, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 19, 'seq_length': 20, 'actions': [1, 1, 0, 2, 2, 0, 2, 1, 2, 2, 0, 0, 2, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 4), (0, 4), (0, 5), (1, 5), (2, 5), (2, 4), (1, 4), (1, 3), (2, 3), (2, 2), (2, 1), (1, 1), (1, 2), (0, 2)], 'first_turn_left': True, 'is_trapped': True}
Episode 1599, score: 4.0, epsilon: 0.92, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 2, 0, 2, 1, 0, 2, 0, 0, 1, 0, 2, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-1, 2), (-1, 3), (0, 3), (1, 3), (1, 4), (2, 4), (2, 5), (1, 5), (0, 5), (0, 4), (-1, 4), (-1, 5), (-1, 6), (-2, 6), (-2, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 1699, score: 3.0, epsilon: 0.92, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [0, 2, 0, 1, 0, 1, 2, 0, 1, 0, 0, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-4, 0), (-4, -1), (-4, -2), (-3, -2), (-3, -1), (-2, -1), (-2, 0), (-2, 1), (-2, 2)], 'first_turn_left': True, 'is_trapped': True}
Episode 1799, score: 0.0, epsilon: 0.91, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 2, 0, 2, 2, 0, 2, 1, 2, 1, 0, 2, 2, 0, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5), (-1, 5), (-1, 6), (0, 6), (1, 6), (1, 5), (1, 4), (2, 4), (2, 3), (1, 3), (1, 2), (1, 1), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 1899, score: 0.0, epsilon: 0.91, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 0, 1, 2, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (-2, 4), (-3, 4), (-3, 5), (-4, 5), (-5, 5), (-5, 4), (-5, 3), (-5, 2), (-4, 2), (-3, 2), (-3, 1), (-2, 1), (-2, 2), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 1999, score: 0.0, epsilon: 0.91, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 2, 0, 1, 1, 0, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (0, 3), (1, 3), (1, 2), (1, 1), (2, 1), (3, 1), (4, 1), (4, 0), (5, 0), (6, 0), (7, 0), (7, 1), (6, 1), (5, 1), (5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 2099, score: 0.0, epsilon: 0.90, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-3, -2), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, -2), (2, -3), (1, -3), (0, -3), (0, -4), (0, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 2199, score: 1.0, epsilon: 0.90, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 0, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (-2, 4), (-2, 5), (-1, 5), (0, 5), (1, 5), (1, 4), (1, 3), (1, 2), (1, 1), (1, 0), (1, -1), (1, -2), (0, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 2299, score: 1.0, epsilon: 0.89, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 1, 2, 0, 2, 1, 0, 0, 2, 2, 0, 0, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, 1), (-4, 2), (-5, 2), (-5, 1), (-6, 1), (-6, 2), (-7, 2), (-7, 1), (-8, 1), (-9, 1), (-10, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 2399, score: 1.0, epsilon: 0.89, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 0, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (-2, 4), (-3, 4), (-4, 4), (-4, 5), (-4, 6), (-4, 7), (-3, 7), (-2, 7), (-1, 7), (-1, 6), (-2, 6), (-3, 6), (-3, 5), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 2499, score: 1.0, epsilon: 0.88, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 1, 2, 0, 0, 1, 0, 1, 2, 1, 2, 0, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (0, 5), (0, 6), (-1, 6), (-2, 6), (-2, 5), (-2, 4), (-3, 4), (-4, 4), (-4, 5), (-5, 5), (-6, 5), (-6, 6), (-7, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 2599, score: 1.0, epsilon: 0.88, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 1, 2, 0, 0, 2, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 4), (-1, 5), (0, 5), (0, 4), (1, 4), (1, 3), (2, 3), (2, 2), (2, 1), (1, 1), (1, 0), (2, 0), (2, -1), (2, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 2699, score: 0.0, epsilon: 0.88, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2), (1, -3), (1, -4), (1, -5), (2, -5), (3, -5), (4, -5), (4, -4), (4, -3), (5, -3), (6, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 2799, score: 3.0, epsilon: 0.87, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 2, 0, 0, 1, 2, 1, 0, 2, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (0, -2), (0, -3), (1, -3), (1, -4), (1, -5), (0, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 2899, score: 3.0, epsilon: 0.87, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 1, 0, 1, 0, 0, 2, 1, 2, 0, 2, 1, 2, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-3, 0), (-3, -1), (-3, -2), (-2, -2), (-2, -1), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -3), (1, -4), (0, -4), (-1, -4), (-1, -3), (0, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 2999, score: 1.0, epsilon: 0.86, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 2, 1, 1, 2, 0, 1, 0, 2, 2, 1, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-5, 2), (-6, 2), (-7, 2), (-7, 1), (-8, 1), (-8, 2), (-8, 3), (-7, 3), (-7, 4), (-8, 4), (-8, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 3099, score: 2.0, epsilon: 0.86, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 16, 'seq_length': 20, 'actions': [0, 2, 2, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (0, 4), (-1, 4), (-2, 4), (-3, 4), (-3, 3), (-3, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 2)], 'first_turn_left': True, 'is_trapped': True}
Episode 3199, score: 1.0, epsilon: 0.85, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 1, 1, 1, 2, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2), (-3, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-3, -2), (-3, -3), (-3, -4), (-4, -4), (-5, -4), (-5, -3), (-6, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 3299, score: 4.0, epsilon: 0.85, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -2), (-3, -2), (-3, -1), (-4, -1), (-4, -2), (-4, -3), (-4, -4), (-3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 3399, score: 5.0, epsilon: 0.85, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 2, 2, 0, 0, 1, 1, 0, 0, 2, 1, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 4), (0, 4), (0, 5), (-1, 5), (-2, 5), (-3, 5), (-3, 4), (-2, 4), (-2, 3), (-2, 2), (-1, 2), (-1, 1), (-2, 1), (-2, 0), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 3499, score: 0.0, epsilon: 0.84, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 0, 1, 0, 2, 1, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-4, 0), (-5, 0), (-5, 1), (-6, 1), (-6, 0), (-7, 0), (-7, -1), (-7, -2), (-6, -2), (-6, -3), (-6, -4), (-5, -4), (-4, -4), (-4, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 3599, score: 1.0, epsilon: 0.84, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 0, 0, 2, 1, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-3, 2), (-4, 2), (-4, 3), (-3, 3), (-3, 4), (-2, 4), (-2, 5), (-3, 5), (-3, 6), (-4, 6), (-4, 7), (-5, 7), (-6, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 3699, score: 0.0, epsilon: 0.83, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 2, 1, 0, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-4, 0), (-4, -1), (-5, -1), (-5, 0), (-6, 0), (-6, 1), (-6, 2), (-5, 2), (-5, 1), (-4, 1), (-4, 2), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 3799, score: 0.0, epsilon: 0.83, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 2, 2, 0, 1, 1, 0, 0, 2, 1, 2, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (0, 3), (0, 2), (1, 2), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (2, 5), (3, 5), (4, 5), (5, 5), (5, 4), (4, 4), (4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 3899, score: 1.0, epsilon: 0.82, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 1, 2, 0, 2, 2, 0, 1, 1, 0, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, -2), (-4, -2), (-4, -1), (-5, -1), (-6, -1), (-7, -1), (-7, -2), (-8, -2), (-8, -3), (-7, -3), (-7, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 3999, score: 1.0, epsilon: 0.82, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3), (2, 2), (3, 2), (4, 2), (4, 3), (3, 3), (3, 4), (3, 5), (2, 5), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 4099, score: 1.0, epsilon: 0.82, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 2), (-2, 2), (-1, 2), (-1, 3), (-2, 3), (-3, 3), (-4, 3), (-4, 4), (-3, 4), (-3, 5), (-3, 6), (-2, 6), (-1, 6), (0, 6), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 4199, score: 1.0, epsilon: 0.81, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 1, 0, 2, 1, 0, 1, 2, 1, 1, 2, 2, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-3, -2), (-4, -2), (-5, -2), (-5, -3), (-5, -4), (-6, -4), (-7, -4), (-8, -4), (-8, -3), (-7, -3), (-6, -3), (-6, -2), (-7, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 4299, score: 1.0, epsilon: 0.81, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 2, 1, 1, 2, 0, 2, 1, 0, 1, 0, 0, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (0, 3), (1, 3), (2, 3), (2, 2), (3, 2), (3, 1), (3, 0), (4, 0), (5, 0), (5, 1), (4, 1), (4, 2), (4, 3), (3, 3), (3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 4399, score: 1.0, epsilon: 0.80, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 2, 0, 1, 0, 0, 2, 1, 2, 2, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-3, -1), (-3, -2), (-4, -2), (-4, -1), (-5, -1), (-6, -1), (-7, -1), (-7, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 4499, score: 1.0, epsilon: 0.80, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 1, 1, 1, 2, 1, 2, 1, 0, 0, 1, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-2, -3), (-3, -3), (-4, -3), (-4, -2), (-4, -1), (-5, -1), (-5, -2), (-5, -3), (-5, -4), (-6, -4), (-6, -5), (-5, -5), (-4, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 4599, score: 0.0, epsilon: 0.80, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 1, 0, 0, 1, 1, 2, 1, 2, 0, 1, 0, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-2, 4), (-2, 5), (-1, 5), (-1, 6), (-1, 7), (-2, 7), (-2, 8), (-2, 9), (-2, 10), (-3, 10)], 'first_turn_left': True, 'is_trapped': False}
Episode 4699, score: 1.0, epsilon: 0.79, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 1, 1, 0, 2, 2, 0, 0, 2, 2, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-3, 0), (-4, 0), (-4, -1), (-5, -1), (-5, 0), (-6, 0), (-6, -1), (-7, -1), (-7, 0), (-7, 1), (-8, 1), (-9, 1), (-9, 0), (-8, 0), (-8, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 4799, score: 4.0, epsilon: 0.79, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (4, -2), (3, -2), (2, -2), (1, -2), (0, -2), (-1, -2), (-2, -2), (-3, -2), (-3, -3), (-2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 4899, score: 4.0, epsilon: 0.78, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 2, 1, 1, 0, 2, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-1, 2), (0, 2), (1, 2), (1, 3), (2, 3), (2, 2), (3, 2), (3, 1), (3, 0), (2, 0), (2, 1), (1, 1), (1, 0), (1, -1), (0, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 4999, score: 1.0, epsilon: 0.78, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 1, 0, 2, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (-1, 4), (-2, 4), (-2, 5), (-3, 5), (-3, 4), (-3, 3), (-2, 3), (-2, 2), (-3, 2), (-3, 1), (-2, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 5099, score: 2.0, epsilon: 0.78, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 2, 2, 0, 0, 2, 1, 2, 1, 2, 0, 2, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 4), (0, 4), (0, 5), (-1, 5), (-1, 6), (-1, 7), (0, 7), (1, 7), (1, 6), (2, 6), (2, 5), (1, 5), (1, 4), (1, 3), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 5199, score: 3.0, epsilon: 0.77, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 2, 0, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-2, -3), (-3, -3), (-3, -4), (-2, -4), (-1, -4), (-1, -5), (-2, -5), (-2, -6), (-2, -7), (-3, -7), (-3, -8)], 'first_turn_left': True, 'is_trapped': False}
Episode 5299, score: 4.0, epsilon: 0.77, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 0, 2, 1, 0, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (3, 2), (4, 2), (4, 3), (4, 4), (3, 4), (2, 4), (2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 5399, score: 3.0, epsilon: 0.77, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (-1, 3), (-2, 3), (-2, 4), (-3, 4), (-4, 4), (-4, 3), (-3, 3), (-3, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 5499, score: 3.0, epsilon: 0.76, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 5599, score: 2.0, epsilon: 0.76, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 15, 'seq_length': 20, 'actions': [0, 1, 0, 1, 1, 1, 0, 0, 2, 0, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-2, -3), (-1, -3), (-1, -2), (0, -2), (0, -1), (-1, -1), (-1, 0), (-1, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 5699, score: 3.0, epsilon: 0.75, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 1, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-3, 1), (-3, 2), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 5799, score: 1.0, epsilon: 0.75, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-2, 1), (-3, 1), (-3, 2), (-3, 3), (-3, 4), (-3, 5), (-3, 6), (-3, 7), (-4, 7), (-4, 8), (-5, 8), (-6, 8), (-7, 8), (-7, 9), (-6, 9)], 'first_turn_left': True, 'is_trapped': False}
Episode 5899, score: 3.0, epsilon: 0.75, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [0, 1, 2, 2, 0, 0, 2, 2, 1, 1, 2, 1, 2, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 4), (-1, 4), (0, 4), (1, 4), (1, 3), (1, 2), (0, 2), (0, 3), (1, 3)], 'first_turn_left': True, 'is_trapped': True}
Episode 5999, score: 2.0, epsilon: 0.74, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 1, 2, 1, 1, 0, 0, 2, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-3, -3), (-4, -3), (-5, -3), (-5, -4), (-4, -4), (-4, -5), (-5, -5), (-6, -5), (-6, -6), (-6, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 6099, score: 0.0, epsilon: 0.74, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 1, 2, 0, 0, 2, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-4, 3), (-4, 2), (-5, 2), (-5, 3), (-6, 3), (-7, 3), (-8, 3), (-9, 3), (-10, 3), (-10, 4), (-10, 5), (-11, 5), (-12, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 6199, score: 4.0, epsilon: 0.74, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 6299, score: 2.0, epsilon: 0.73, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 1, 1, 1, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, -1), (3, -1), (3, -2), (3, -3), (3, -4), (3, -5), (3, -6), (3, -7), (4, -7), (4, -8), (5, -8)], 'first_turn_left': True, 'is_trapped': False}
Episode 6399, score: 0.0, epsilon: 0.73, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 2, 1, 1, 1, 1, 2, 0, 1, 2, 2, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 2), (-3, 3), (-3, 4), (-3, 5), (-3, 6), (-2, 6), (-2, 7), (-2, 8), (-1, 8), (-1, 7), (-1, 6), (0, 6), (1, 6), (2, 6), (2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 6499, score: 2.0, epsilon: 0.73, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 19, 'seq_length': 20, 'actions': [0, 1, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, -2), (-2, -2), (-1, -2), (0, -2), (0, -3), (1, -3), (1, -2), (1, -1), (0, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 6599, score: 3.0, epsilon: 0.72, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 2, 2, 0, 2, 0, 0, 2, 2, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, -1), (3, -1), (3, -2), (4, -2), (4, -1), (5, -1), (5, -2), (5, -3), (5, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 6699, score: 1.0, epsilon: 0.72, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 0, 2, 2, 1, 0, 1, 1, 0, 0, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (2, -1), (2, -2), (2, -3), (3, -3), (4, -3), (5, -3), (5, -2), (4, -2), (3, -2), (3, -1), (3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 6799, score: 0.0, epsilon: 0.71, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, -2), (0, -2), (0, -3), (0, -4), (1, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 6899, score: 0.0, epsilon: 0.71, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 2, 0, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2), (-3, 1), (-4, 1), (-5, 1), (-5, 2), (-5, 3), (-4, 3), (-4, 4), (-4, 5), (-4, 6), (-4, 7), (-5, 7), (-6, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 6999, score: 0.0, epsilon: 0.71, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-2, 3), (-3, 3), (-4, 3), (-5, 3), (-5, 4), (-4, 4), (-4, 5), (-3, 5), (-2, 5), (-1, 5), (0, 5), (1, 5), (1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 7099, score: 3.0, epsilon: 0.70, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (1, 4), (1, 5), (0, 5), (0, 6), (-1, 6), (-1, 5), (-1, 4), (-2, 4), (-3, 4), (-3, 3), (-2, 3), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 7199, score: 3.0, epsilon: 0.70, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 1, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (-1, 6), (-1, 7), (0, 7), (0, 6), (1, 6), (2, 6), (2, 5), (1, 5), (0, 5), (0, 4), (1, 4), (1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 7299, score: 2.0, epsilon: 0.70, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 2, 2, 0, 2, 1, 2, 2, 0, 1, 1, 0, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, 1), (-4, 1), (-4, 2), (-4, 3), (-3, 3), (-3, 2), (-2, 2), (-1, 2), (0, 2), (0, 3), (-1, 3), (-2, 3), (-2, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 7399, score: 3.0, epsilon: 0.69, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 0, 1, 2, 0, 1, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 2), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, -2), (1, -3), (2, -3), (2, -2), (2, -1), (2, 0), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 7499, score: 0.0, epsilon: 0.69, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 1, 2, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-3, -3), (-4, -3), (-4, -4), (-4, -5), (-5, -5), (-6, -5), (-7, -5), (-7, -4), (-7, -3), (-8, -3), (-9, -3), (-9, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 7599, score: 4.0, epsilon: 0.69, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 1, 0, 0, 2, 0, 0, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (-1, -2), (-1, -3), (0, -3), (0, -4), (1, -4), (1, -3), (2, -3), (3, -3), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 7699, score: 2.0, epsilon: 0.68, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2), (1, -3), (1, -4), (1, -5), (2, -5), (2, -6), (3, -6), (4, -6), (4, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 7799, score: 2.0, epsilon: 0.68, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 2, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-5, 2), (-5, 1), (-4, 1), (-3, 1), (-2, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 7899, score: 3.0, epsilon: 0.68, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (0, -6), (1, -6), (1, -5), (0, -5), (0, -4), (0, -3), (0, -2), (0, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 7999, score: 2.0, epsilon: 0.67, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, -2), (2, -2), (2, -3), (1, -3), (1, -4), (0, -4), (0, -3), (-1, -3), (-1, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 8099, score: 2.0, epsilon: 0.67, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 2, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-5, 2), (-6, 2), (-6, 1), (-6, 0), (-5, 0), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 8199, score: 2.0, epsilon: 0.67, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-4, 0), (-4, -1), (-5, -1), (-5, 0), (-6, 0), (-6, 1), (-5, 1), (-5, 2), (-5, 3), (-4, 3), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 8299, score: 0.0, epsilon: 0.66, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 0, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-3, -3), (-3, -2), (-3, -1), (-4, -1), (-5, -1), (-5, -2), (-5, -3), (-6, -3), (-6, -4), (-7, -4), (-8, -4), (-8, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 8399, score: 2.0, epsilon: 0.66, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 1, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-3, 0), (-3, 1), (-2, 1), (-2, 2), (-3, 2), (-4, 2), (-4, 1), (-4, 0), (-4, -1), (-4, -2), (-3, -2), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 8499, score: 2.0, epsilon: 0.66, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 2, 2, 1, 1, 2, 2, 0, 0, 1, 1, 1, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-2, 1), (-2, 2), (-2, 3), (-2, 4), (-1, 4), (-1, 3), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (-1, 8), (-1, 9), (0, 9)], 'first_turn_left': True, 'is_trapped': False}
Episode 8599, score: 0.0, epsilon: 0.65, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 0, 2, 1, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 4), (-2, 5), (-1, 5), (-1, 6), (0, 6), (0, 5), (1, 5), (1, 4), (0, 4), (0, 3), (1, 3), (1, 2), (2, 2), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 8699, score: 3.0, epsilon: 0.65, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 14, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 2, 0, 2, 1, 2, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-3, 1), (-3, 2), (-3, 3), (-2, 3), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': True}
Episode 8799, score: 3.0, epsilon: 0.65, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 2, 2, 1, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (3, -1), (4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 8899, score: 1.0, epsilon: 0.64, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 0, 2, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (4, 3), (5, 3), (5, 4), (4, 4), (3, 4), (3, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 8999, score: 3.0, epsilon: 0.64, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (1, 3), (0, 3), (0, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 9099, score: 2.0, epsilon: 0.64, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 15, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 2, 0, 0, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2), (1, -1), (0, -1), (-1, -1)], 'first_turn_left': True, 'is_trapped': True}
Episode 9199, score: 3.0, epsilon: 0.64, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, 1), (-1, 2), (0, 2)], 'first_turn_left': True, 'is_trapped': True}
Episode 9299, score: 0.0, epsilon: 0.63, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 0, 1, 2, 0, 0, 1, 1, 0, 2, 1, 2, 2, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (-1, 3), (-2, 3), (-2, 4), (-3, 4), (-3, 3), (-3, 2), (-3, 1), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 9399, score: 0.0, epsilon: 0.63, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (-1, 8), (-1, 9), (-1, 10), (-1, 11), (-1, 12), (-1, 13), (-1, 14), (0, 14), (1, 14), (1, 15), (1, 16)], 'first_turn_left': True, 'is_trapped': False}
Episode 9499, score: 2.0, epsilon: 0.63, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 2, 0, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (1, -3), (2, -3), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 9599, score: 3.0, epsilon: 0.62, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 1, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 9699, score: 3.0, epsilon: 0.62, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 1, 2, 2, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-2, 3), (-3, 3), (-4, 3), (-4, 4), (-5, 4), (-5, 3), (-5, 2), (-4, 2), (-3, 2), (-2, 2), (-1, 2), (-1, 1), (-2, 1), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 9799, score: 1.0, epsilon: 0.62, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-2, 3), (-3, 3), (-3, 2), (-2, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -3), (1, -3), (2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 9899, score: 0.0, epsilon: 0.61, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 19, 'seq_length': 20, 'actions': [1, 0, 0, 2, 1, 1, 0, 0, 1, 2, 1, 1, 0, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-2, -1), (-2, -2), (-2, -3), (-1, -3), (-1, -2), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 9999, score: 2.0, epsilon: 0.61, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (1, -2), (2, -2), (3, -2), (4, -2), (5, -2), (5, -1), (5, 0), (5, 1), (5, 2), (6, 2), (6, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 10099, score: 1.0, epsilon: 0.61, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 1, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-2, -2), (-2, -3), (-2, -4), (-2, -5), (-3, -5), (-3, -6), (-2, -6), (-2, -7), (-2, -8), (-2, -9), (-2, -10), (-1, -10), (-1, -11), (0, -11)], 'first_turn_left': True, 'is_trapped': False}
Episode 10199, score: 5.0, epsilon: 0.60, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 10299, score: 3.0, epsilon: 0.60, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 0, 1, 2, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (-2, 5), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 10399, score: 2.0, epsilon: 0.60, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 1, 0, 1, 1, 0, 0, 2, 2, 0, 2, 1, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-2, 3), (-3, 3), (-4, 3), (-5, 3), (-5, 2), (-4, 2), (-4, 1), (-5, 1), (-5, 0), (-6, 0), (-7, 0), (-7, 1), (-6, 1), (-6, 2), (-7, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 10499, score: 2.0, epsilon: 0.60, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 10599, score: 2.0, epsilon: 0.59, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (2, -1), (3, -1), (3, 0), (2, 0), (1, 0), (1, 1), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 10699, score: 4.0, epsilon: 0.59, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 1, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 10799, score: 1.0, epsilon: 0.59, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 0, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-5, 0), (-5, -1), (-5, -2), (-5, -3), (-5, -4), (-5, -5), (-5, -6), (-5, -7), (-5, -8)], 'first_turn_left': True, 'is_trapped': False}
Episode 10899, score: 2.0, epsilon: 0.58, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3), (3, 3), (3, 4), (3, 5), (4, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 10999, score: 2.0, epsilon: 0.58, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 2, 2, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, -2), (3, -2), (4, -2), (5, -2), (6, -2), (6, -3), (5, -3), (5, -4), (4, -4), (4, -3), (3, -3), (3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 11099, score: 5.0, epsilon: 0.58, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (1, 4), (0, 4), (0, 3), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 11199, score: 5.0, epsilon: 0.58, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 2, 0, 0, 1, 0, 1, 2, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, -1), (3, -1), (3, 0), (3, 1), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 11299, score: 2.0, epsilon: 0.57, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 0, 2, 0, 0, 1, 2, 0, 1, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (-1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 11399, score: 1.0, epsilon: 0.57, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 2, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-1, -3), (0, -3), (1, -3), (1, -2), (2, -2), (3, -2), (4, -2), (5, -2), (5, -3), (5, -4), (6, -4), (6, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 11499, score: 3.0, epsilon: 0.57, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 1, 0, 0, 2, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-3, -2), (-3, -3), (-2, -3), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 11599, score: 1.0, epsilon: 0.56, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-3, 0), (-3, -1), (-4, -1), (-4, -2), (-3, -2), (-2, -2), (-1, -2), (0, -2), (1, -2), (2, -2), (2, -3), (3, -3), (4, -3), (4, -4), (3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 11699, score: 2.0, epsilon: 0.56, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-5, 2), (-6, 2), (-7, 2), (-7, 3), (-7, 4), (-6, 4), (-6, 3), (-5, 3), (-5, 4), (-4, 4), (-4, 3), (-3, 3), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 11799, score: 3.0, epsilon: 0.56, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 0, 1, 0, 0, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -3), (-3, -4), (-2, -4), (-2, -3), (-1, -3), (0, -3), (1, -3), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 11899, score: 2.0, epsilon: 0.56, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 1, 2, 0, 1, 1, 1, 2, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (3, 0), (3, -1), (4, -1), (5, -1), (6, -1), (7, -1), (7, -2), (7, -3), (6, -3), (6, -4), (5, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 11999, score: 4.0, epsilon: 0.55, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 1, 0, 0, 2, 1, 0, 2, 0, 0, 1, 1, 1, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 12099, score: 3.0, epsilon: 0.55, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 2, 0, 1, 2, 0, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (2, 2), (2, 3), (2, 4), (3, 4), (3, 5), (2, 5), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 12199, score: 3.0, epsilon: 0.55, reward_max: 7.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (-1, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 12299, score: 3.0, epsilon: 0.55, reward_max: 7.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (1, -3), (1, -4), (2, -4), (2, -3), (3, -3), (4, -3), (5, -3), (5, -2)], 'first_turn_left': True, 'is_trapped': False}
found new highest reward =  8.0
{'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 12399, score: 3.0, epsilon: 0.54, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 1, 0, 2, 2, 0, 0, 2, 2, 0, 2, 1, 1, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-4, 2), (-5, 2), (-5, 1), (-6, 1), (-6, 2), (-7, 2), (-7, 3), (-7, 4), (-7, 5), (-6, 5), (-6, 4), (-6, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 12499, score: 2.0, epsilon: 0.54, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 2, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 12599, score: 0.0, epsilon: 0.54, reward_max: 8.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4), (-4, 4), (-5, 4), (-6, 4), (-7, 4), (-7, 5), (-8, 5), (-8, 6), (-8, 7), (-8, 8), (-8, 9), (-7, 9), (-6, 9)], 'first_turn_left': True, 'is_trapped': False}
Episode 12699, score: 2.0, epsilon: 0.53, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-1, -4), (0, -4), (0, -3), (1, -3), (1, -2), (1, -1), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 12799, score: 8.0, epsilon: 0.53, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 8.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 12899, score: 1.0, epsilon: 0.53, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 1, 2, 1, 0, 2, 0, 1, 0, 0, 2, 1, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-3, 0), (-3, 1), (-4, 1), (-4, 2), (-5, 2), (-6, 2), (-6, 1), (-5, 1), (-5, 0), (-5, -1), (-5, -2), (-6, -2), (-6, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 12999, score: 2.0, epsilon: 0.53, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (-1, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 13099, score: 2.0, epsilon: 0.52, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (3, -2), (4, -2), (5, -2), (6, -2), (6, -1), (5, -1), (4, -1), (3, -1), (2, -1), (2, 0), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 13199, score: 2.0, epsilon: 0.52, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (2, 3), (2, 4), (1, 4), (1, 3), (0, 3), (0, 4), (0, 5), (0, 6), (1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 13299, score: 2.0, epsilon: 0.52, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 2, 1, 0, 2, 0, 1, 2, 1, 2, 2, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (0, 4), (1, 4), (1, 5), (2, 5), (2, 6), (2, 7), (3, 7), (4, 7), (4, 6), (3, 6), (3, 5), (4, 5), (4, 4), (3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 13399, score: 0.0, epsilon: 0.52, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [0, 2, 2, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (0, 4), (-1, 4), (-2, 4), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 13499, score: 3.0, epsilon: 0.51, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (0, -3), (1, -3), (2, -3), (3, -3), (3, -2), (2, -2), (1, -2), (1, -1), (2, -1), (2, 0), (3, 0), (3, -1), (4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 13599, score: 1.0, epsilon: 0.51, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-3, -2), (-2, -2), (-1, -2), (0, -2), (1, -2), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 13699, score: 3.0, epsilon: 0.51, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 1, 0, 0, 2, 1, 2, 0, 1, 0, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (2, -2), (2, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (2, 3), (1, 3), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 13799, score: 1.0, epsilon: 0.51, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-3, -4), (-3, -5), (-2, -5), (-1, -5), (-1, -4), (0, -4), (0, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 13899, score: 0.0, epsilon: 0.50, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 2, 2, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -3), (-1, -3), (-1, -4), (-2, -4), (-3, -4), (-3, -5), (-2, -5), (-2, -6), (-3, -6), (-3, -7), (-4, -7), (-4, -6), (-5, -6)], 'first_turn_left': True, 'is_trapped': False}
Episode 13999, score: 4.0, epsilon: 0.50, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 1, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 14099, score: 1.0, epsilon: 0.50, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (0, 4), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 14199, score: 1.0, epsilon: 0.50, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-3, -2), (-3, -3), (-3, -4), (-3, -5), (-2, -5), (-1, -5), (0, -5), (1, -5), (2, -5), (3, -5), (4, -5), (4, -6), (3, -6)], 'first_turn_left': True, 'is_trapped': False}
Episode 14299, score: 1.0, epsilon: 0.49, reward_max: 8.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 1, 0, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (-1, 4), (-2, 4), (-3, 4), (-3, 5), (-2, 5), (-1, 5), (0, 5), (0, 4), (0, 3), (1, 3), (1, 4), (2, 4), (3, 4), (4, 4), (5, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 14399, score: 2.0, epsilon: 0.49, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 2, 0, 2, 0, 0, 1, 2, 1, 0, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -3), (3, -3), (3, -2), (3, -1), (4, -1), (5, -1), (5, 0), (4, 0), (3, 0), (2, 0), (2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 14499, score: 3.0, epsilon: 0.49, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 14599, score: 2.0, epsilon: 0.49, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 2, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -3), (-4, -3), (-5, -3), (-6, -3), (-7, -3), (-8, -3), (-9, -3), (-10, -3), (-10, -2), (-10, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 14699, score: 2.0, epsilon: 0.48, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 2, 0, 0, 1, 1, 2, 1, 2, 2, 0, 0, 1, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (0, 3), (0, 4), (-1, 4), (-2, 4), (-3, 4), (-3, 5), (-3, 6), (-2, 6), (-2, 5), (-1, 5), (-1, 6), (-1, 7), (0, 7), (0, 6), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 14799, score: 4.0, epsilon: 0.48, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -3), (0, -3), (0, -4), (1, -4), (2, -4), (2, -3), (2, -2), (2, -1), (1, -1), (1, 0), (2, 0), (3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 14899, score: 4.0, epsilon: 0.48, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 14999, score: 2.0, epsilon: 0.48, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 15099, score: 2.0, epsilon: 0.48, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 2, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 4), (0, 5), (-1, 5), (-2, 5), (-3, 5), (-3, 6), (-3, 7), (-2, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 15199, score: 2.0, epsilon: 0.47, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 15299, score: 1.0, epsilon: 0.47, reward_max: 8.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 10, 'seq_length': 20, 'actions': [1, 0, 1, 0, 1, 0, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, 1), (-2, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 15399, score: 3.0, epsilon: 0.47, reward_max: 8.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, -2), (2, -3), (3, -3), (3, -2), (3, -1), (3, 0), (4, 0), (4, -1), (4, -2), (5, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 15499, score: 2.0, epsilon: 0.47, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 19, 'seq_length': 20, 'actions': [0, 1, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, 1), (-3, 2), (-4, 2), (-5, 2), (-5, 1), (-4, 1), (-4, 0), (-4, -1), (-3, -1), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 15599, score: 0.0, epsilon: 0.46, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [0, 2, 1, 2, 0, 1, 0, 2, 0, 1, 0, 0, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (0, 3), (0, 4), (0, 5), (-1, 5), (-1, 6), (-2, 6), (-3, 6), (-3, 5), (-2, 5), (-2, 4), (-1, 4), (-1, 5)], 'first_turn_left': True, 'is_trapped': True}
Episode 15699, score: 4.0, epsilon: 0.46, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 0, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-3, 0), (-4, 0), (-5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 15799, score: 2.0, epsilon: 0.46, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 15899, score: 4.0, epsilon: 0.46, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, -1), (-4, -2), (-3, -2), (-3, -3), (-2, -3), (-2, -2), (-1, -2), (-1, -1), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 15999, score: 3.0, epsilon: 0.45, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 2, 1, 2, 0, 0, 1, 2, 0, 0, 1, 0, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-2, 2), (-1, 2), (-1, 3), (-2, 3), (-3, 3), (-3, 4), (-4, 4), (-4, 3), (-4, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 16099, score: 3.0, epsilon: 0.45, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 0, 1, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 16199, score: 2.0, epsilon: 0.45, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 16299, score: 2.0, epsilon: 0.45, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (2, 4), (1, 4), (0, 4), (0, 3), (1, 3), (1, 2)], 'first_turn_left': True, 'is_trapped': True}
Episode 16399, score: 0.0, epsilon: 0.45, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 2, 1, 0, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-2, -5), (-2, -6), (-2, -7), (-3, -7), (-4, -7), (-4, -8), (-3, -8), (-3, -9), (-2, -9)], 'first_turn_left': True, 'is_trapped': False}
Episode 16499, score: 4.0, epsilon: 0.44, reward_max: 8.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 16599, score: 1.0, epsilon: 0.44, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 2, 2, 0, 0, 1, 2, 2, 0, 2, 2, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -3), (0, -3), (0, -4), (1, -4), (2, -4), (2, -5), (1, -5), (1, -6), (0, -6), (0, -5), (-1, -5), (-2, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 16699, score: 3.0, epsilon: 0.44, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 2, 0, 2, 0, 0, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (1, 4), (1, 3), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 16799, score: 1.0, epsilon: 0.44, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 2, 0, 1, 0, 2, 0, 2, 0, 0, 1, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-4, 3), (-4, 2), (-5, 2), (-5, 1), (-6, 1), (-6, 0), (-5, 0), (-4, 0), (-4, -1), (-3, -1), (-3, 0), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 16899, score: 4.0, epsilon: 0.44, reward_max: 8.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 2, 0, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (1, 4), (0, 4), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 16999, score: 1.0, epsilon: 0.43, reward_max: 8.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 10, 'seq_length': 20, 'actions': [1, 0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, 1), (0, 1)], 'first_turn_left': True, 'is_trapped': True}
found new highest reward =  9.0
{'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (3, 0), (3, 1), (2, 1), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 17099, score: 5.0, epsilon: 0.43, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 1, 2, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -3), (2, -3), (2, -2), (3, -2), (3, -3), (4, -3), (4, -4), (4, -5), (3, -5), (2, -5), (2, -4), (3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 17199, score: 2.0, epsilon: 0.43, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 2, 0, 1, 0, 1, 0, 1, 2, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, -2), (2, -2), (3, -2), (3, -1), (3, 0), (2, 0), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 17299, score: 2.0, epsilon: 0.43, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 15, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, -2), (2, -3), (1, -3), (0, -3), (0, -2), (1, -2), (2, -2)], 'first_turn_left': True, 'is_trapped': True}
Episode 17399, score: 4.0, epsilon: 0.42, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (-1, 3), (-2, 3), (-3, 3), (-3, 2), (-3, 1), (-2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 17499, score: 3.0, epsilon: 0.42, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-3, 3), (-3, 2), (-2, 2), (-2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 17599, score: 5.0, epsilon: 0.42, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 17699, score: 4.0, epsilon: 0.42, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 0, 2, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 17799, score: 1.0, epsilon: 0.42, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 2, 0, 0, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-3, -2), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 17899, score: 1.0, epsilon: 0.41, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 0, 1, 1, 1, 0, 1, 0, 0, 2, 2, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (-1, 3), (-2, 3), (-3, 3), (-4, 3), (-4, 2), (-4, 1), (-3, 1), (-3, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 17999, score: 3.0, epsilon: 0.41, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 18099, score: 1.0, epsilon: 0.41, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 13, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 1, 2, 1, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (0, -3), (-1, -3), (-2, -3), (-2, -2), (-1, -2), (0, -2)], 'first_turn_left': True, 'is_trapped': True}
Episode 18199, score: 0.0, epsilon: 0.41, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 0, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (-1, 5), (-2, 5), (-2, 4), (-3, 4), (-4, 4), (-4, 5), (-4, 6), (-4, 7), (-4, 8), (-5, 8), (-5, 9), (-5, 10), (-5, 11), (-5, 12)], 'first_turn_left': True, 'is_trapped': False}
Episode 18299, score: 1.0, epsilon: 0.41, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 2, 0, 1, 2, 0, 0, 1, 1, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -3), (-3, -4), (-4, -4), (-4, -5), (-3, -5), (-2, -5), (-1, -5), (0, -5), (0, -6), (1, -6), (1, -5), (1, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 18399, score: 5.0, epsilon: 0.40, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 18499, score: 2.0, epsilon: 0.40, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 2, 1, 2, 2, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (4, 3), (4, 2), (3, 2), (3, 1), (3, 0), (3, -1), (2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 18599, score: 0.0, epsilon: 0.40, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 0, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-3, 3), (-4, 3), (-4, 4), (-3, 4), (-3, 5), (-3, 6), (-3, 7), (-4, 7), (-5, 7), (-6, 7), (-7, 7), (-8, 7), (-9, 7), (-10, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 18699, score: 3.0, epsilon: 0.40, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 18799, score: 3.0, epsilon: 0.40, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-2, -3), (-1, -3), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 18899, score: 1.0, epsilon: 0.39, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (4, 0), (5, 0), (6, 0), (6, 1), (5, 1), (4, 1), (3, 1), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 18999, score: 0.0, epsilon: 0.39, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (-1, 8), (-2, 8), (-2, 9), (-2, 10), (-2, 11), (-2, 12), (-2, 13), (-2, 14), (-2, 15), (-1, 15), (0, 15)], 'first_turn_left': True, 'is_trapped': False}
Episode 19099, score: 4.0, epsilon: 0.39, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 2, 2, 0, 0, 2, 0, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (0, -3), (0, -4), (1, -4), (1, -3), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 19199, score: 0.0, epsilon: 0.39, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-2, -2), (-2, -3), (-2, -4), (-2, -5), (-2, -6), (-1, -6), (0, -6), (1, -6), (1, -7), (2, -7), (2, -6), (3, -6), (3, -7), (4, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 19299, score: 0.0, epsilon: 0.39, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 2, 0, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 2), (-4, 2), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -4), (1, -4), (1, -3), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 19399, score: 3.0, epsilon: 0.39, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 19499, score: 2.0, epsilon: 0.38, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (3, -1), (3, 0), (4, 0), (4, 1), (3, 1), (2, 1), (2, 0), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 19599, score: 2.0, epsilon: 0.38, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 1, 0, 0, 2, 2, 0, 0, 1, 1, 0, 0, 2, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -3), (-2, -3), (-1, -3), (0, -3), (0, -2), (-1, -2), (-1, -1), (0, -1), (1, -1), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 19699, score: 3.0, epsilon: 0.38, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 2, 0, 0, 2, 0, 0, 1, 1, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-2, -2), (-2, -3), (-1, -3), (-1, -4), (0, -4), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 19799, score: 0.0, epsilon: 0.38, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 1, 0, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-1, -3), (-1, -2), (0, -2), (1, -2), (2, -2), (2, -3), (2, -4), (2, -5), (2, -6), (2, -7), (2, -8), (1, -8)], 'first_turn_left': True, 'is_trapped': False}
Episode 19899, score: 2.0, epsilon: 0.38, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (4, -1), (4, -2), (5, -2), (5, -3), (5, -4), (5, -5), (4, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 19999, score: 3.0, epsilon: 0.37, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (2, 4), (2, 5), (1, 5), (0, 5), (-1, 5), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 20099, score: 4.0, epsilon: 0.37, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 0, 1, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 20199, score: 1.0, epsilon: 0.37, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-3, -4), (-3, -3), (-4, -3), (-4, -2), (-5, -2), (-5, -1), (-5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 20299, score: 0.0, epsilon: 0.37, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (-1, 3), (-1, 4), (-1, 5), (-1, 6), (-1, 7), (-1, 8), (-1, 9), (-1, 10), (-1, 11), (0, 11), (1, 11), (2, 11), (3, 11), (4, 11)], 'first_turn_left': True, 'is_trapped': False}
Episode 20399, score: 3.0, epsilon: 0.37, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 20499, score: 3.0, epsilon: 0.37, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 0, 0, 1, 2, 1, 0, 2, 0, 0, 1, 0, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-4, 0), (-5, 0), (-5, -1), (-6, -1), (-6, -2), (-5, -2), (-4, -2), (-4, -1), (-3, -1), (-2, -1), (-2, 0), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 20599, score: 2.0, epsilon: 0.36, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 1, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, -2), (4, -2), (4, -1), (5, -1), (5, 0), (4, 0), (3, 0), (2, 0), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 20699, score: 1.0, epsilon: 0.36, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 1, 1, 1, 0, 2, 1, 2, 2, 0, 1, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-4, -1), (-5, -1), (-5, -2), (-6, -2), (-7, -2), (-7, -1), (-6, -1), (-6, 0), (-6, 1), (-5, 1), (-4, 1), (-3, 1), (-2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 20799, score: 0.0, epsilon: 0.36, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 13, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (1, -2), (2, -2), (2, -1), (1, -1), (0, -1), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 20899, score: 4.0, epsilon: 0.36, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-4, 1), (-5, 1), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 20999, score: 5.0, epsilon: 0.36, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 21099, score: 0.0, epsilon: 0.35, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 2, 0, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, 0), (-3, 0), (-3, -1), (-3, -2), (-4, -2), (-5, -2), (-6, -2), (-7, -2), (-8, -2), (-9, -2), (-9, -1), (-9, 0), (-9, 1), (-8, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 21199, score: 3.0, epsilon: 0.35, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 2, 0, 0, 1, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (3, -1), (3, 0), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 21299, score: 1.0, epsilon: 0.35, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (1, -2), (1, -1), (0, -1), (-1, -1)], 'first_turn_left': True, 'is_trapped': True}
Episode 21399, score: 0.0, epsilon: 0.35, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 2, 0, 0, 1, 2, 0, 1, 1, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -3), (-2, -3), (-1, -3), (-1, -4), (0, -4), (1, -4), (2, -4), (3, -4), (3, -5), (2, -5), (2, -6), (1, -6)], 'first_turn_left': True, 'is_trapped': False}
Episode 21499, score: 3.0, epsilon: 0.35, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, 0), (-3, 0), (-3, -1), (-3, -2), (-4, -2), (-4, -1), (-5, -1), (-5, 0), (-4, 0), (-4, 1), (-3, 1), (-3, 2), (-2, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 21599, score: 2.0, epsilon: 0.35, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 2, 0, 2, 0, 0, 1, 2, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, -2), (3, -2), (3, -3), (4, -3), (4, -2), (4, -1), (5, -1), (5, 0), (5, 1), (4, 1), (4, 0), (3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 21699, score: 3.0, epsilon: 0.34, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 21799, score: 4.0, epsilon: 0.34, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-3, -3), (-4, -3), (-5, -3), (-5, -4), (-4, -4), (-3, -4), (-2, -4), (-1, -4), (-1, -3), (-1, -2), (0, -2), (0, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 21899, score: 3.0, epsilon: 0.34, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 0, 1, 1, 2, 0, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 21999, score: 5.0, epsilon: 0.34, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 0, 0, 2, 2, 1, 1, 1, 0, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (2, -1), (2, -2), (2, -3), (2, -4), (2, -5), (3, -5), (3, -4), (3, -3), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 22099, score: 2.0, epsilon: 0.34, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 2, 2, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (2, -1), (3, -1), (4, -1), (4, 0), (5, 0), (5, -1), (6, -1), (6, -2), (7, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 22199, score: 6.0, epsilon: 0.34, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 4), (0, 4), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 22299, score: 1.0, epsilon: 0.33, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 2, 2, 1, 2, 0, 2, 0, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -3), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0), (-2, 0), (-2, 1), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 22399, score: 5.0, epsilon: 0.33, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 0, 2, 2, 0, 2, 0, 2, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (3, 2), (3, 1), (4, 1), (4, 0), (5, 0), (5, -1), (5, -2), (4, -2), (4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 22499, score: 2.0, epsilon: 0.33, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 0, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, 0), (-3, 0), (-3, -1), (-3, -2), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 22599, score: 3.0, epsilon: 0.33, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 19, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 2, 1, 1, 2, 2, 0, 2, 2, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (3, 0), (4, 0), (4, -1), (3, -1), (3, -2), (2, -2), (2, -1), (2, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 22699, score: 4.0, epsilon: 0.33, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, 0), (4, 0), (5, 0), (5, -1), (4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 22799, score: 2.0, epsilon: 0.33, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 2, 2, 0, 2, 0, 2, 1, 1, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, -2), (1, -2), (1, -3), (0, -3), (0, -4), (-1, -4), (-2, -4), (-3, -4), (-4, -4), (-4, -5), (-5, -5), (-5, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 22899, score: 4.0, epsilon: 0.33, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -1), (-2, 0), (-3, 0), (-3, 1), (-2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 22999, score: 3.0, epsilon: 0.32, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 23099, score: 5.0, epsilon: 0.32, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, -1), (3, -1), (3, -2), (2, -2), (2, -3), (1, -3), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 23199, score: 4.0, epsilon: 0.32, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 23299, score: 1.0, epsilon: 0.32, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 13, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (1, 1), (1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 23399, score: 2.0, epsilon: 0.32, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 4), (1, 4), (1, 5), (2, 5), (2, 6), (1, 6), (0, 6), (0, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 23499, score: 4.0, epsilon: 0.32, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 0, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 23599, score: 1.0, epsilon: 0.31, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 2, 0, 0, 1, 2, 0, 2, 2, 0, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-3, 1), (-3, 0), (-3, -1), (-4, -1), (-4, -2), (-5, -2), (-5, -1), (-6, -1), (-6, 0), (-5, 0), (-5, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 23699, score: 2.0, epsilon: 0.31, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 0, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-2, 4), (-3, 4), (-3, 5), (-2, 5), (-2, 6), (-1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 23799, score: 5.0, epsilon: 0.31, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 23899, score: 4.0, epsilon: 0.31, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 0, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -1), (-4, -1), (-4, -2), (-4, -3), (-3, -3), (-2, -3), (-1, -3), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 23999, score: 2.0, epsilon: 0.31, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4), (3, 4), (2, 4), (2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 24099, score: 3.0, epsilon: 0.31, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 24199, score: 3.0, epsilon: 0.31, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-2, -3), (-2, -2), (-1, -2), (0, -2)], 'first_turn_left': True, 'is_trapped': True}
Episode 24299, score: 2.0, epsilon: 0.30, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (4, -1), (4, -2), (5, -2), (5, -1), (5, 0), (6, 0), (7, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 24399, score: 2.0, epsilon: 0.30, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 19, 'seq_length': 20, 'actions': [1, 0, 1, 1, 0, 2, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-5, 1), (-6, 1), (-6, 0), (-5, 0), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, 1), (-2, 1), (-2, 2)], 'first_turn_left': True, 'is_trapped': True}
Episode 24499, score: 6.0, epsilon: 0.30, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (1, 4), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 24599, score: 0.0, epsilon: 0.30, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (-1, -7), (-1, -8), (-1, -9), (-2, -9), (-3, -9), (-4, -9), (-5, -9), (-6, -9), (-7, -9), (-8, -9)], 'first_turn_left': True, 'is_trapped': False}
Episode 24699, score: 0.0, epsilon: 0.30, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 1, 1, 0, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (-1, 5), (-2, 5), (-3, 5), (-3, 6), (-2, 6), (-2, 7), (-2, 8), (-2, 9), (-2, 10), (-3, 10), (-4, 10), (-4, 11), (-4, 12), (-4, 13)], 'first_turn_left': True, 'is_trapped': False}
Episode 24799, score: 3.0, epsilon: 0.30, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 2, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (0, 4), (0, 3), (-1, 3), (-2, 3), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 24899, score: 2.0, epsilon: 0.30, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 24999, score: 3.0, epsilon: 0.29, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 25099, score: 2.0, epsilon: 0.29, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (4, -2), (4, -3), (4, -4), (4, -5), (5, -5), (6, -5), (6, -6), (6, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 25199, score: 5.0, epsilon: 0.29, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, 1), (3, 2), (2, 2), (2, 3), (1, 3), (1, 2), (0, 2), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 25299, score: 2.0, epsilon: 0.29, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (2, 2), (1, 2), (1, 1), (0, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 25399, score: 4.0, epsilon: 0.29, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 0, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 4), (-4, 4), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 25499, score: 3.0, epsilon: 0.29, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (3, 0), (3, -1), (2, -1), (2, -2), (1, -2), (1, -3), (0, -3), (0, -2), (-1, -2), (-2, -2), (-2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 25599, score: 3.0, epsilon: 0.29, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4), (-3, 5), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 25699, score: 6.0, epsilon: 0.28, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 25799, score: 1.0, epsilon: 0.28, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (1, -3), (2, -3), (3, -3), (4, -3), (5, -3), (6, -3), (7, -3), (7, -2), (8, -2), (8, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 25899, score: 4.0, epsilon: 0.28, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 2, 2, 1, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, 1), (4, 1), (4, 0), (4, -1), (3, -1), (3, -2), (2, -2), (2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 25999, score: 4.0, epsilon: 0.28, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 16, 'seq_length': 20, 'actions': [1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-3, 0), (-3, -1), (-2, -1), (-2, -2), (-1, -2), (-1, -1), (-1, 0), (-2, 0), (-2, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 26099, score: 1.0, epsilon: 0.28, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, -2), (2, -3), (2, -4), (2, -5), (1, -5), (0, -5), (-1, -5), (-2, -5), (-3, -5), (-3, -6)], 'first_turn_left': True, 'is_trapped': False}
Episode 26199, score: 1.0, epsilon: 0.28, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 12, 'seq_length': 20, 'actions': [1, 0, 1, 0, 2, 0, 0, 1, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, 1), (-2, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 26299, score: 1.0, epsilon: 0.28, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 1, 2, 2, 0, 2, 0, 2, 2, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, -2), (2, -2), (2, -3), (1, -3), (1, -4), (0, -4), (0, -3), (-1, -3), (-2, -3), (-2, -4), (-3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 26399, score: 1.0, epsilon: 0.27, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (5, -1), (6, -1), (6, -2), (7, -2), (8, -2), (9, -2), (10, -2), (11, -2), (12, -2), (12, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 26499, score: 2.0, epsilon: 0.27, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (2, -1), (2, -2), (1, -2), (1, -3), (0, -3), (0, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 26599, score: 2.0, epsilon: 0.27, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 2, 2, 0, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (3, 0), (3, -1), (3, -2), (3, -3), (2, -3), (2, -2), (1, -2), (1, -3), (0, -3), (0, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 26699, score: 2.0, epsilon: 0.27, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 1, 1, 0, 2, 0, 0, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-2, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 26799, score: 3.0, epsilon: 0.27, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-1, -4), (0, -4), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 26899, score: 2.0, epsilon: 0.27, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (5, -1), (5, 0), (6, 0), (7, 0), (8, 0), (9, 0), (10, 0), (10, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 26999, score: 4.0, epsilon: 0.27, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 1, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 27099, score: 3.0, epsilon: 0.27, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 0, 1, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (3, 1), (3, 0), (3, -1), (4, -1), (4, -2), (4, -3), (3, -3), (3, -2), (2, -2), (2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 27199, score: 5.0, epsilon: 0.26, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 2, 2, 0, 2, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, 1), (4, 1), (4, 0), (5, 0), (5, -1), (5, -2), (4, -2), (4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 27299, score: 3.0, epsilon: 0.26, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3), (3, 3), (3, 2), (2, 2), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 27399, score: 3.0, epsilon: 0.26, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, 1), (3, 2), (4, 2), (4, 1), (5, 1), (5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 27499, score: 2.0, epsilon: 0.26, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -3), (-3, -3), (-3, -2), (-4, -2), (-5, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 27599, score: 2.0, epsilon: 0.26, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (0, -3), (0, -4), (-1, -4), (-1, -5), (-2, -5), (-2, -4), (-3, -4), (-3, -3), (-2, -3), (-2, -2), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 27699, score: 0.0, epsilon: 0.26, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 0, 2, 0, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (-1, 3), (-2, 3), (-2, 2), (-3, 2), (-3, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 27799, score: 4.0, epsilon: 0.26, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (2, 2), (2, 3), (2, 4), (1, 4), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 27899, score: 5.0, epsilon: 0.26, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 27999, score: 3.0, epsilon: 0.25, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 28099, score: 3.0, epsilon: 0.25, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 1, 0, 0, 2, 1, 0, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 28199, score: 1.0, epsilon: 0.25, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 2, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, -2), (3, -3), (4, -3), (4, -4), (5, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 28299, score: 0.0, epsilon: 0.25, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (-1, 6), (-1, 7), (-1, 8), (0, 8), (1, 8), (2, 8), (3, 8), (4, 8), (5, 8), (6, 8), (6, 9), (5, 9), (5, 10)], 'first_turn_left': True, 'is_trapped': False}
Episode 28399, score: 2.0, epsilon: 0.25, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 2, 0, 2, 2, 0, 0, 1, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -3), (1, -3), (1, -4), (2, -4), (3, -4), (3, -5), (2, -5), (2, -6), (1, -6), (1, -5), (0, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 28499, score: 4.0, epsilon: 0.25, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (-1, 5), (-2, 5), (-3, 5), (-4, 5), (-4, 4), (-3, 4), (-2, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-2, 1), (-2, 0), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 28599, score: 2.0, epsilon: 0.25, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-2, -1), (-2, -2), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 28699, score: 3.0, epsilon: 0.25, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 2, 2, 0, 2, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, 1), (4, 1), (4, 0), (5, 0), (5, -1), (4, -1), (3, -1), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 28799, score: 6.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 28899, score: 3.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (1, -3), (2, -3), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 28999, score: 1.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-2, 4), (-3, 4), (-4, 4), (-5, 4), (-5, 5), (-4, 5), (-4, 6), (-3, 6), (-3, 5), (-2, 5), (-2, 6), (-1, 6), (-1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 29099, score: 4.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (2, 0), (2, -1), (3, -1), (4, -1), (4, -2), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 29199, score: 3.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 18, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 2, 1, 2, 0, 2, 1, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, -1), (2, -2), (1, -2), (1, -3), (0, -3), (-1, -3), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': True}
Episode 29299, score: 2.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 2, 2, 0, 0, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (2, -1), (2, -2), (3, -2), (3, -3), (4, -3), (5, -3), (5, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 29399, score: 5.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (3, 2), (3, 3), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 29499, score: 3.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-2, 3), (-2, 4), (-2, 5), (-3, 5), (-4, 5), (-4, 6), (-3, 6), (-3, 7), (-2, 7), (-2, 6), (-1, 6), (-1, 5), (0, 5), (0, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 29599, score: 0.0, epsilon: 0.24, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-6, 1), (-6, 0), (-6, -1), (-6, -2), (-5, -2), (-5, -3), (-6, -3), (-6, -4), (-6, -5), (-6, -6), (-6, -7), (-5, -7), (-4, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 29699, score: 3.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 29799, score: 0.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (1, -2), (2, -2), (3, -2), (4, -2), (5, -2), (6, -2), (7, -2), (8, -2), (8, -3), (8, -4), (8, -5), (8, -6), (8, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 29899, score: 0.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-6, 1), (-6, 0), (-6, -1), (-6, -2), (-6, -3), (-6, -4), (-6, -5), (-6, -6), (-7, -6), (-8, -6), (-9, -6), (-10, -6), (-10, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 29999, score: 2.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 15, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2), (1, -1), (0, -1), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 30099, score: 5.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-1, 3), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 30199, score: 1.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0, 2, 0, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (1, 2), (2, 2), (2, 3), (2, 4), (3, 4), (3, 3), (3, 2), (4, 2), (4, 1), (5, 1), (5, 0), (4, 0), (4, -1), (3, -1), (3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 30299, score: 2.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (-1, -3), (-1, -4), (-2, -4), (-2, -3), (-3, -3), (-3, -2), (-4, -2), (-4, -1), (-3, -1), (-3, 0), (-2, 0), (-2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 30399, score: 2.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 2, 0, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (3, 1), (3, 2), (2, 2), (1, 2), (1, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 30499, score: 3.0, epsilon: 0.23, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (2, 0), (2, -1), (3, -1), (3, 0), (4, 0), (5, 0), (5, -1), (4, -1), (4, -2), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 30599, score: 4.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 30699, score: 1.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-1, -4), (0, -4), (0, -3), (0, -2), (0, -1), (1, -1), (1, -2), (2, -2), (2, -3), (1, -3), (1, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 30799, score: 2.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (-1, -7), (-1, -8), (-1, -9), (-1, -10)], 'first_turn_left': True, 'is_trapped': False}
Episode 30899, score: 0.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 12, 'seq_length': 20, 'actions': [0, 2, 1, 1, 2, 2, 0, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (0, 4), (0, 3), (1, 3), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': True}
Episode 30999, score: 2.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 31099, score: 2.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 2, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 31199, score: 5.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 31299, score: 2.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 2, 0, 1, 0, 0, 2, 2, 1, 2, 0, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 2), (-5, 2), (-6, 2), (-6, 1), (-5, 1), (-5, 0), (-6, 0), (-7, 0), (-7, 1), (-8, 1), (-8, 0), (-8, -1), (-8, -2), (-8, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 31399, score: 4.0, epsilon: 0.22, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (1, 5), (1, 4), (1, 3), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 31499, score: 4.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 5), (-1, 6), (-1, 7), (-1, 8), (-1, 9), (-2, 9), (-2, 8), (-2, 7), (-2, 6), (-2, 5), (-2, 4), (-2, 3), (-2, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 31599, score: 5.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 0, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 31699, score: 2.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 0, 1, 0, 2, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (1, -3), (1, -2), (2, -2), (2, -1), (3, -1), (3, -2), (4, -2), (4, -3), (3, -3), (3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 31799, score: 2.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, 0), (-2, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 31899, score: 1.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-3, 2), (-3, 3), (-4, 3), (-4, 2), (-4, 1), (-3, 1), (-3, 0), (-4, 0), (-4, -1), (-5, -1), (-5, 0), (-6, 0), (-6, 1), (-5, 1), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 31999, score: 3.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 6), (3, 7), (4, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 32099, score: 5.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, -1), (3, -1), (3, -2), (2, -2), (2, -3), (2, -4), (2, -5), (1, -5), (1, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 32199, score: 1.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 2), (-5, 2), (-5, 3), (-4, 3), (-4, 4), (-3, 4), (-2, 4), (-2, 3), (-3, 3), (-3, 2), (-2, 2), (-1, 2), (-1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 32299, score: 3.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-1, -4), (0, -4), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 32399, score: 2.0, epsilon: 0.21, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (5, -1), (6, -1), (7, -1), (7, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 32499, score: 2.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 2, 0, 0, 1, 0, 2, 2, 0, 1, 0, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-4, 0), (-4, -1), (-3, -1), (-2, -1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 32599, score: 2.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 15, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -2), (1, -2), (1, -1), (0, -1), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 32699, score: 3.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, 0), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 32799, score: 5.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (2, 2), (1, 2), (1, 1), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 32899, score: 0.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [0, 1, 0, 2, 2, 0, 0, 1, 0, 1, 2, 0, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, 1), (-4, 1), (-4, 0), (-4, -1), (-3, -1), (-2, -1), (-2, -2), (-1, -2), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 32999, score: 1.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1, 2, 1, 1, 2, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (0, -4), (1, -4), (1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (2, -1), (3, -1), (3, -2), (4, -2), (5, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 33099, score: 2.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 1, 2, 1, 1, 1, 0, 0, 1, 2, 2, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-3, 0), (-3, 1), (-3, 2), (-3, 3), (-3, 4), (-4, 4), (-4, 3), (-4, 2), (-5, 2), (-5, 3), (-5, 4), (-5, 5), (-5, 6), (-4, 6), (-4, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 33199, score: 4.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (0, -4), (1, -4), (1, -3), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 33299, score: 5.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 0, 0, 2, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, 0), (3, 1), (2, 1), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 33399, score: 5.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 2, 0, 2, 2, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-2, 3), (-1, 3), (-1, 2), (0, 2), (0, 3), (0, 4), (1, 4), (1, 3), (2, 3), (2, 2), (1, 2), (1, 1), (2, 1), (2, 0), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 33499, score: 2.0, epsilon: 0.20, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-2, 3), (-1, 3), (-1, 2), (0, 2), (0, 3), (1, 3), (1, 2), (2, 2), (2, 3), (3, 3), (3, 2), (4, 2), (4, 3), (4, 4), (3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 33599, score: 5.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 2, 1, 2, 0, 0, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, -2), (-3, -3), (-4, -3), (-4, -2), (-5, -2), (-5, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 33699, score: 4.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 2, 0, 0, 1, 2, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3), (2, 4), (1, 4), (0, 4), (0, 5), (0, 6), (1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 33799, score: 6.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 33899, score: 4.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 33999, score: 1.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 13, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (1, 1), (1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 34099, score: 1.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 2, 2, 1, 0, 0, 1, 2, 0, 1, 1, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (0, 4), (0, 3), (0, 2), (1, 2), (1, 3), (1, 4), (2, 4), (2, 5), (2, 6), (2, 7), (3, 7), (3, 6), (4, 6), (4, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 34199, score: 2.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (1, -2), (2, -2), (3, -2), (4, -2), (4, -3), (3, -3), (3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 34299, score: 5.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3), (-2, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 34399, score: 5.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 34499, score: 4.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -2), (-3, -2), (-3, -1), (-2, -1), (-2, 0), (-2, 1), (-2, 2), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 34599, score: 6.0, epsilon: 0.19, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 18, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (2, 2), (1, 2), (1, 1), (0, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 34699, score: 4.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3), (2, 2), (3, 2), (4, 2), (4, 1), (3, 1), (3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 34799, score: 5.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (2, 8), (2, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 34899, score: 2.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 34999, score: 2.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 2, 0, 0, 2, 1, 0, 0, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 35099, score: 5.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-4, 0), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 35199, score: 2.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 35299, score: 1.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 0, 2, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-2, -2), (-3, -2), (-3, -3), (-2, -3), (-1, -3), (0, -3), (1, -3), (1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 35399, score: 2.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 35499, score: 3.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-2, 3), (-1, 3), (-1, 2), (0, 2), (0, 3), (1, 3), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (2, 0), (2, -1), (1, -1), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 35599, score: 5.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 35699, score: 4.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 0, 2, 2, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, -2), (1, -2), (1, -3), (0, -3), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -2), (-2, -1), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 35799, score: 5.0, epsilon: 0.18, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 35899, score: 1.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (1, -3), (2, -3), (3, -3), (4, -3), (5, -3), (6, -3), (7, -3), (7, -2), (7, -1), (6, -1), (6, -2), (5, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 35999, score: 1.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-2, 3), (-1, 3), (-1, 2), (0, 2), (0, 3), (1, 3), (1, 2), (2, 2), (2, 3), (3, 3), (3, 2), (4, 2), (4, 3), (5, 3), (6, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 36099, score: 4.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 0, 0, 1, 1, 1, 0, 0, 2, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 36199, score: 4.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (0, -5), (0, -4), (0, -3), (0, -2), (0, -1), (1, -1), (1, -2), (1, -3), (2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 36299, score: 3.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 36399, score: 0.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 0, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-4, -1), (-4, -2), (-3, -2), (-2, -2), (-2, -1), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 36499, score: 5.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 36599, score: 3.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, 1), (-3, 1), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 36699, score: 2.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 36799, score: 5.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (0, 4), (0, 3), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 36899, score: 1.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (0, 4), (0, 5), (0, 6), (-1, 6), (-1, 5), (-2, 5), (-2, 6), (-3, 6), (-3, 7), (-2, 7), (-2, 8), (-1, 8), (-1, 7), (0, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 36999, score: 2.0, epsilon: 0.17, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 0, 2, 0, 0, 1, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-2, 3), (-2, 4), (-3, 4), (-3, 3), (-3, 2), (-4, 2), (-4, 1), (-4, 0), (-3, 0), (-3, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 37099, score: 5.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-4, 0), (-5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 37199, score: 2.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 1, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 2), (-1, 1), (-2, 1), (-3, 1), (-3, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 4), (-4, 4), (-5, 4), (-5, 5), (-5, 6), (-6, 6), (-6, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 37299, score: 3.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 1, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 37399, score: 4.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -4), (0, -4), (1, -4), (1, -3), (2, -3), (2, -2), (2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 37499, score: 5.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-3, 2), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 37599, score: 2.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (-1, 6), (-1, 7), (-2, 7), (-2, 6), (-2, 5), (-2, 4), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 37699, score: 6.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 0, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 4), (-4, 4), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 37799, score: 5.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 37899, score: 2.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 37999, score: 5.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 38099, score: 1.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-2, 2), (-2, 3), (-2, 4), (-1, 4), (0, 4), (0, 5), (-1, 5), (-2, 5), (-3, 5), (-3, 4), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 38199, score: 5.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 38299, score: 4.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 38399, score: 6.0, epsilon: 0.16, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 38499, score: 2.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-1, -3), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 38599, score: 2.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 38699, score: 5.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 0, 0, 1, 1, 2, 0, 0, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 38799, score: 3.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3), (3, 3), (4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 38899, score: 5.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 38999, score: 5.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 39099, score: 5.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-4, 0), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 39199, score: 5.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-4, 3), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 39299, score: 4.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 1, 1, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -2), (-3, -2), (-4, -2), (-5, -2), (-6, -2), (-6, -1), (-6, 0), (-6, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 39399, score: 4.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 0, 1, 0, 1, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (2, 4), (1, 4), (0, 4), (0, 5), (0, 6), (0, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 39499, score: 5.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 39599, score: 1.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (-1, 6), (-1, 7), (-2, 7), (-2, 6), (-2, 5), (-2, 4), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 39699, score: 5.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (1, 4), (1, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 39799, score: 3.0, epsilon: 0.15, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 39899, score: 2.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, -2), (1, -3), (1, -4), (1, -5), (1, -6), (1, -7), (2, -7), (3, -7), (3, -6), (2, -6), (2, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 39999, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 40099, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 40199, score: 3.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 40299, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 40399, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 40499, score: 3.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (0, -3), (0, -4), (0, -5), (0, -6), (0, -7), (1, -7), (1, -6), (1, -5), (1, -4), (1, -3), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 40599, score: 0.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-3, 0), (-3, 1), (-4, 1), (-5, 1), (-6, 1), (-7, 1), (-8, 1), (-9, 1), (-10, 1), (-11, 1), (-12, 1), (-13, 1), (-13, 0), (-13, -1), (-13, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 40699, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (2, 0), (2, -1), (3, -1), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 40799, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 40899, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 40999, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 41099, score: 2.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (5, -1), (5, 0), (6, 0), (6, -1), (7, -1), (7, -2), (6, -2), (6, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 41199, score: 2.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 2, 2, 0, 0, 2, 2, 0, 2, 2, 1, 0, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (0, 3), (0, 2), (1, 2), (1, 3), (2, 3), (2, 2), (3, 2), (3, 1), (2, 1), (1, 1), (1, 0), (2, 0), (3, 0), (4, 0), (4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 41299, score: 5.0, epsilon: 0.14, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 41399, score: 5.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 41499, score: 3.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 2, 0, 2, 1, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-1, 2), (-1, 3), (0, 3), (1, 3), (1, 4), (0, 4), (-1, 4), (-2, 4), (-2, 3), (-3, 3), (-3, 2), (-3, 1), (-3, 0), (-2, 0), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 41599, score: 4.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -2), (-3, -2), (-4, -2), (-4, -1), (-3, -1), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 41699, score: 3.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 1, 1, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-3, -3), (-4, -3), (-5, -3), (-6, -3), (-7, -3), (-7, -2), (-6, -2), (-6, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 41799, score: 3.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-3, 3), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 41899, score: 5.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 2, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 41999, score: 4.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -2), (-3, -2), (-3, -1), (-2, -1), (-2, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 42099, score: 6.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (4, 0), (3, 0), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 42199, score: 5.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (4, 0), (3, 0), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 42299, score: 5.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 42399, score: 4.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (4, 0), (4, 1), (3, 1), (3, 0), (2, 0), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 42499, score: 2.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 0, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (4, 0), (4, 1), (5, 1), (5, 2), (4, 2), (3, 2), (2, 2), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 42599, score: 1.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 6), (3, 5), (4, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 42699, score: 5.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (0, 7), (0, 6), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 42799, score: 5.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 42899, score: 5.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 42999, score: 5.0, epsilon: 0.13, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 43099, score: 4.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (5, -1), (5, 0), (5, 1), (5, 2), (5, 3), (4, 3), (4, 2), (4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 43199, score: 1.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (5, -1), (6, -1), (7, -1), (8, -1), (9, -1), (10, -1), (11, -1), (11, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 43299, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 43399, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 43499, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 2, 0, 0, 1, 2, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (3, 0), (3, 1), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 43599, score: 6.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-4, 0), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 43699, score: 3.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 0, 1, 2, 0, 2, 2, 0, 2, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -3), (1, -3), (1, -4), (0, -4), (0, -3), (0, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 43799, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 43899, score: 6.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 43999, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 44099, score: 6.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-5, 2), (-5, 3), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 44199, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 2, 1, 0, 2, 0, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (2, -1), (3, -1), (3, -2), (4, -2), (4, -1), (4, 0), (5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 44299, score: 3.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 0, 0, 1, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-4, -1), (-5, -1), (-6, -1), (-6, 0), (-6, 1), (-6, 2), (-6, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 44399, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (0, 7), (0, 6), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 44499, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (2, -1), (2, -2), (1, -2), (1, -3), (1, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 44599, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 44699, score: 5.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 44799, score: 4.0, epsilon: 0.12, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 2, 0, 0, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, -2), (-4, -2), (-4, -1), (-5, -1), (-5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 44899, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 1, 0, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, -1), (3, -1), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 44999, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 45099, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 45199, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 45299, score: 4.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (2, 7), (2, 6), (3, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 45399, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 45499, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 45599, score: 7.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 45699, score: 4.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 0, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (7, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 45799, score: 4.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 2, 0, 0, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (3, 0), (3, 1), (2, 1), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 45899, score: 4.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (4, 1), (4, 0), (4, -1), (3, -1), (2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 45999, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 46099, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-4, 3), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 46199, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 46299, score: 3.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 46399, score: 1.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, -2), (3, -3), (3, -4), (2, -4), (1, -4), (0, -4), (-1, -4), (-2, -4), (-2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 46499, score: 7.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 46599, score: 5.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 46699, score: 2.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 46799, score: 7.0, epsilon: 0.11, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 46899, score: 2.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 46999, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 47099, score: 6.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 47199, score: 5.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 47299, score: 4.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 47399, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 47499, score: 5.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 47599, score: 0.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-2, 3), (-3, 3), (-4, 3), (-5, 3), (-6, 3), (-7, 3), (-8, 3), (-9, 3), (-10, 3), (-11, 3), (-12, 3), (-13, 3), (-14, 3), (-15, 3), (-16, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 47699, score: 5.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 47799, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 47899, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 47999, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 48099, score: 4.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 2, 2, 0, 0, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (3, -1), (3, -2), (4, -2), (4, -1), (4, 0), (3, 0), (2, 0), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 48199, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 48299, score: 2.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 48399, score: 2.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 48499, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 48599, score: 4.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 1, 0, 2, 0, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (3, 1), (3, 2), (4, 2), (4, 3), (3, 3), (3, 4), (4, 4), (4, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 48699, score: 6.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-2, 4), (-3, 4), (-3, 5), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 48799, score: 2.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 2, 2, 1, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-4, 0), (-5, 0), (-5, -1), (-4, -1), (-3, -1), (-2, -1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 48899, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 48999, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 49099, score: 7.0, epsilon: 0.10, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 49199, score: 7.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 49299, score: 3.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 2, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (3, 0), (3, -1), (4, -1), (4, 0), (4, 1), (3, 1), (3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 49399, score: 3.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 49499, score: 3.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 49599, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 49699, score: 2.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 2, 0, 0, 2, 2, 0, 0, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-1, -4), (0, -4), (0, -3), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 49799, score: 6.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 1, 1, 2, 0, 2, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (4, 3), (4, 2), (3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 49899, score: 7.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 49999, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 50099, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 50199, score: 3.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (2, -1), (2, -2), (1, -2), (1, -3), (0, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 50299, score: 7.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 50399, score: 6.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 50499, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 50599, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 50699, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 50799, score: 0.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 0, 0, 2, 1, 0, 0, 1, 1, 2, 2, 0, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-5, 1), (-5, 0), (-4, 0), (-3, 0), (-2, 0), (-2, -1), (-3, -1), (-3, -2), (-4, -2), (-4, -3), (-3, -3), (-3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 50899, score: 3.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -3), (-2, -3), (-1, -3), (-1, -2), (0, -2), (0, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 50999, score: 6.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 51099, score: 7.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 51199, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 51299, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 51399, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 2, 0, 0, 1, 2, 0, 0, 2, 0, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 51499, score: 5.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 51599, score: 7.0, epsilon: 0.09, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 51699, score: 6.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 16, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (2, 2), (1, 2), (1, 1), (0, 1)], 'first_turn_left': True, 'is_trapped': True}
Episode 51799, score: 2.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 51899, score: 7.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 51999, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (3, 2), (3, 3), (2, 3), (1, 3), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 52099, score: 7.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 52199, score: 6.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 52299, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 52399, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 2, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 4), (0, 4), (1, 4), (1, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 52499, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-3, 2), (-3, 3), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 52599, score: 3.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (3, 2), (2, 2), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 52699, score: 3.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, 0), (-3, 0), (-3, -1), (-3, -2), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 52799, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (0, 4), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 52899, score: 7.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 52999, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 0, 0, 2, 2, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, 0), (3, 1), (2, 1), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 53099, score: 7.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 53199, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (0, 4), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 53299, score: 7.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 53399, score: 3.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 0, 1, 2, 1, 1, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (2, -2), (2, -3), (2, -4), (2, -5), (2, -6), (2, -7), (2, -8), (1, -8), (1, -7), (0, -7)], 'first_turn_left': True, 'is_trapped': False}
Episode 53499, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 53599, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-2, 4), (-2, 5), (-2, 6), (-1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 53699, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 4), (-2, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 53799, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 53899, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (0, 4), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 53999, score: 3.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -4), (-3, -4), (-3, -3), (-4, -3), (-4, -2), (-3, -2), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 54099, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (0, 4), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 54199, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 54299, score: 5.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (1, 4), (1, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 54399, score: 7.0, epsilon: 0.08, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 54499, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-4, 3), (-5, 3), (-5, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 54599, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (1, 4), (1, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 54699, score: 7.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 54799, score: 7.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0, 0, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (0, 4), (-1, 4), (-1, 3), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 54899, score: 6.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (4, 0), (4, 1), (4, 2), (3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 54999, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 55099, score: 4.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 1, 0, 0, 1, 1, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (-1, -2), (-1, -3), (-2, -3), (-2, -2), (-3, -2), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 55199, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 2, 2, 0, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (1, 3), (2, 3), (2, 4), (1, 4), (1, 5), (2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 55299, score: 7.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 55399, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 0, 0, 2, 2, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 55499, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 55599, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-1, 4), (0, 4), (0, 5), (1, 5), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 55699, score: 7.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 55799, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 55899, score: 7.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 55999, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 56099, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 56199, score: 7.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 56299, score: 7.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 56399, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 56499, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 56599, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 56699, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 56799, score: 4.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 2, 2, 0, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2), (7, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 56899, score: 3.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 56999, score: 2.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 2, 2, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-3, 2), (-3, 3), (-2, 3), (-2, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 57099, score: 2.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 5), (-1, 5), (-1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 57199, score: 3.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 57299, score: 3.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (1, 4), (1, 3), (2, 3), (2, 4), (3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 57399, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 57499, score: 2.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9)], 'first_turn_left': True, 'is_trapped': False}
Episode 57599, score: 4.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 2, 2, 0, 2, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3), (3, 3), (3, 4), (3, 5), (2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 57699, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 57799, score: 5.0, epsilon: 0.07, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 57899, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 57999, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 58099, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 58199, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 58299, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 58399, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 58499, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 58599, score: 3.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 1, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-1, 2), (-1, 3), (0, 3), (0, 2), (1, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (5, 0), (4, 0), (4, -1), (3, -1), (3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 58699, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (2, 0), (2, -1), (2, -2), (2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 58799, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 58899, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 58999, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 59099, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 59199, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 59299, score: 3.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 59399, score: 1.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 2, 0, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (-2, 5), (-2, 4), (-2, 3), (-3, 3), (-4, 3), (-5, 3), (-6, 3), (-7, 3), (-7, 2), (-7, 1), (-7, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 59499, score: 4.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (2, 0), (2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 59599, score: 1.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 1, 1, 0, 1, 0, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-2, 4), (-3, 4), (-3, 3), (-2, 3), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 59699, score: 2.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 2, 0, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-2, 3), (-2, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 59799, score: 2.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -3), (-1, -3), (-1, -4), (-2, -4), (-2, -3), (-3, -3), (-3, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 59899, score: 1.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (-1, -7), (0, -7), (1, -7), (2, -7), (3, -7), (4, -7), (5, -7), (5, -8)], 'first_turn_left': True, 'is_trapped': False}
Episode 59999, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 60099, score: 3.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 60199, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 60299, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 60399, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 60499, score: 4.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 60599, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 60699, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 60799, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 60899, score: 3.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2), (7, 2), (8, 2), (9, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 60999, score: 6.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (2, 3), (2, 2), (3, 2), (3, 1), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 61099, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 61199, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 61299, score: 2.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 61399, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 61499, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 61599, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 61699, score: 5.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 61799, score: 7.0, epsilon: 0.06, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 61899, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 61999, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 1, 1, 0, 2, 2, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (1, 3), (2, 3), (2, 2), (3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 62099, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 62199, score: 4.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (0, 4), (-1, 4), (-2, 4), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 62299, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 62399, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (1, 4), (1, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 62499, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 62599, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 62699, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 62799, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 62899, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 62999, score: 3.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (5, -1), (6, -1), (7, -1), (8, -1), (9, -1), (9, 0), (8, 0), (7, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 63099, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 63199, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 63299, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 63399, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 63499, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 63599, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 63699, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 63799, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 63899, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 63999, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 64099, score: 3.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 64199, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 64299, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-1, 5), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 64399, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 64499, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 64599, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 64699, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 64799, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 64899, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 64999, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 65099, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 65199, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 65299, score: 0.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 0, 1, 1, 0, 0, 1, 2, 0, 2, 2, 0, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-3, 2), (-4, 2), (-5, 2), (-5, 1), (-4, 1), (-3, 1), (-3, 0), (-2, 0), (-2, -1), (-3, -1), (-3, -2), (-4, -2), (-4, -1), (-5, -1), (-5, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 65399, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 2, 0, 0, 1, 0, 2, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, -2), (3, -2), (3, -3), (4, -3), (4, -2), (4, -1), (3, -1), (3, 0), (2, 0), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 65499, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 65599, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 65699, score: 2.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 0, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-3, -2), (-4, -2), (-5, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 65799, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 65899, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 65999, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 66099, score: 2.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (2, 4), (1, 4), (0, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 66199, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 66299, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 66399, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 66499, score: 7.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 66599, score: 3.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 2, 2, 0, 2, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (2, 0), (2, -1), (3, -1), (3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 66699, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 66799, score: 5.0, epsilon: 0.05, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 66899, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-2, 4), (-3, 4), (-4, 4), (-5, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 66999, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67099, score: 4.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 2, 0, 2, 0, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (2, 1), (2, 2), (3, 2), (3, 3), (2, 3), (1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67199, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67299, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67399, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67499, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67599, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67699, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67799, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -3), (0, -3), (0, -4), (-1, -4), (-1, -5), (0, -5), (1, -5), (1, -4), (2, -4), (2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67899, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 67999, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 68099, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 68199, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 68299, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-4, 0), (-5, 0), (-6, 0), (-7, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 68399, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 68499, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 68599, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 68699, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-3, -2), (-3, -3), (-3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 68799, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 68899, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 68999, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-3, 1), (-3, 2), (-3, 3), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 69099, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 69199, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 69299, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 69399, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 4), (-1, 5), (-1, 6), (0, 6), (1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 69499, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 69599, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 69699, score: 7.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 69799, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 69899, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 69999, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 70099, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 70199, score: 0.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-2, -3), (-3, -3), (-4, -3), (-5, -3), (-6, -3), (-7, -3), (-8, -3), (-9, -3), (-10, -3), (-11, -3), (-12, -3), (-13, -3), (-14, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 70299, score: 1.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 15, 'seq_length': 20, 'actions': [0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 2, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-2, -3), (-1, -3), (0, -3), (0, -2), (-1, -2), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 70399, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 2), (-2, 3), (-3, 3), (-3, 2), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (1, -3), (1, -2), (0, -2), (0, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 70499, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (2, 4), (2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 70599, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 70699, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 4), (-2, 4), (-2, 5), (-1, 5), (-1, 4), (0, 4), (0, 5), (1, 5), (1, 6), (0, 6), (-1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 70799, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 70899, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 70999, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 71099, score: 1.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 2, 0, 2, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 4), (0, 4), (0, 5), (-1, 5), (-2, 5), (-2, 4), (-2, 3), (-2, 2), (-1, 2), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 71199, score: 1.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 17, 'seq_length': 20, 'actions': [1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 2, 0, 2, 2, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 5), (0, 5), (1, 5), (2, 5), (3, 5), (3, 4), (2, 4), (2, 3), (1, 3), (1, 4), (1, 5)], 'first_turn_left': True, 'is_trapped': True}
Episode 71299, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (-1, 9), (-1, 8), (-1, 7), (-1, 6), (-1, 5), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 71399, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 71499, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 71599, score: 4.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (-1, 10), (-1, 9), (-1, 8), (-1, 7), (-1, 6), (-1, 5), (-1, 4), (-1, 3), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 71699, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 71799, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 71899, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 71999, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 72099, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-3, -2), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 72199, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 72299, score: 4.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (2, 0), (2, -1), (2, -2), (1, -2), (1, -3), (2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 72399, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (3, -1), (3, -2), (3, -3), (3, -4), (4, -4), (4, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 72499, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 1, 1, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (3, -1), (3, -2), (3, -3), (2, -3), (2, -4), (3, -4)], 'first_turn_left': True, 'is_trapped': False}
Episode 72599, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 2, 2, 0, 0, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (2, -1), (2, -2), (3, -2), (4, -2), (4, -1), (4, 0), (4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 72699, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (3, 0), (4, 0), (4, 1), (4, 2), (3, 2), (3, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 72799, score: 3.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (1, 4), (2, 4), (2, 5), (3, 5), (3, 4), (4, 4), (4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 72899, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 72999, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 73099, score: 2.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 2, 2, 0, 2, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (3, 2), (4, 2), (4, 1), (4, 0), (3, 0), (3, -1), (2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 73199, score: 6.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 2), (-2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 73299, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 73399, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2), (-3, 1), (-2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 73499, score: 5.0, epsilon: 0.04, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-1, 3), (-2, 3), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 73599, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, -1), (3, -1), (3, -2), (3, -3), (3, -4), (3, -5), (3, -6), (3, -7), (3, -8), (3, -9), (3, -10)], 'first_turn_left': True, 'is_trapped': False}
Episode 73699, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, 1), (3, 2), (2, 2), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 73799, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-2, 4), (-1, 4), (0, 4), (1, 4), (1, 3), (1, 2), (1, 1), (1, 0), (1, -1), (1, -2), (1, -3), (1, -4), (2, -4), (2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 73899, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 73999, score: 0.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 1, 1, 0, 0, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (1, 3), (1, 2), (2, 2), (2, 1), (1, 1), (1, 0), (1, -1), (1, -2), (2, -2), (2, -1), (3, -1), (3, -2), (4, -2), (4, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 74099, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 74199, score: 4.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 0, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 74299, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-3, -2), (-3, -3), (-4, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 74399, score: 4.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 0, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-3, 1), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 74499, score: 1.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 0, 0, 1, 1, 2, 0, 2, 0, 0, 1, 0, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, -1), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -3), (3, -3), (3, -2), (3, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 74599, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 74699, score: 4.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-4, -1), (-4, 0), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 74799, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 74899, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 74999, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 75099, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, 0), (-2, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 75199, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 75299, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-3, 4), (-3, 5), (-3, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 75399, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-3, 4), (-2, 4), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 75499, score: 6.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 75599, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3), (-2, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 75699, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 75799, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 75899, score: 4.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 75999, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 76099, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 76199, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (2, 8), (2, 7)], 'first_turn_left': True, 'is_trapped': False}
Episode 76299, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 76399, score: 6.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (2, 5), (2, 4), (3, 4), (3, 3), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 76499, score: 4.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 76599, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-4, 3), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 76699, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 11, 'seq_length': 20, 'actions': [0, 1, 0, 2, 0, 0, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-3, -1), (-2, -1), (-1, -1), (-1, 0), (-2, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 76799, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 76899, score: 3.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (0, -3), (0, -4), (0, -5), (0, -6), (0, -7), (0, -8), (0, -9), (0, -10), (0, -11), (0, -12), (0, -13)], 'first_turn_left': True, 'is_trapped': False}
Episode 76999, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 77099, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 77199, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 77299, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 77399, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 77499, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 77599, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 77699, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 77799, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 77899, score: 1.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 2), (-3, 3), (-3, 4), (-3, 5), (-3, 6), (-3, 7), (-3, 8), (-3, 9), (-3, 10), (-3, 11), (-3, 12), (-2, 12), (-2, 11), (-1, 11), (-1, 12)], 'first_turn_left': True, 'is_trapped': False}
Episode 77999, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78099, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78199, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78299, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78399, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 78499, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78599, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78699, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78799, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78899, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 78999, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 79099, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 79199, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 79299, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 79399, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 79499, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 79599, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 79699, score: 3.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 1, 2, 2, 0, 2, 2, 0, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-3, -3), (-3, -2), (-4, -2), (-4, -1), (-3, -1), (-3, 0), (-3, 1), (-4, 1), (-5, 1), (-6, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 79799, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 79899, score: 4.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (2, -1), (2, -2), (3, -2), (3, -3), (2, -3), (2, -4), (1, -4), (1, -3), (0, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 79999, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 80099, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 80199, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 80299, score: 4.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 0, 0, 1, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 80399, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 80499, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 80599, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 80699, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 80799, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 9, 'seq_length': 20, 'actions': [0, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-2, -1), (-1, -1), (-1, 0), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 80899, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 80999, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 81099, score: 0.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4), (-4, 4), (-5, 4), (-6, 4), (-6, 5), (-6, 6), (-6, 7), (-6, 8), (-5, 8)], 'first_turn_left': True, 'is_trapped': False}
Episode 81199, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3), (-2, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 81299, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (0, -6), (0, -5), (0, -4), (0, -3), (0, -2), (0, -1), (1, -1), (1, -2), (2, -2), (2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 81399, score: 3.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 81499, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 81599, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 19, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 2, 0, 2, 1, 2, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (3, -2), (2, -2), (2, -1), (2, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 81699, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 81799, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 81899, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 81999, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 82099, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 82199, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 82299, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 82399, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 82499, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 82599, score: 7.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 82699, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 82799, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 82899, score: 3.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-2, -4), (-2, -3), (-3, -3), (-3, -4), (-3, -5), (-2, -5), (-1, -5), (0, -5), (0, -4), (0, -3), (0, -2), (0, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 82999, score: 2.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 2, 2, 1, 0, 2, 2, 0, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -1), (-3, 0), (-4, 0), (-4, 1), (-3, 1), (-3, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 83099, score: 3.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-3, -1), (-4, -1), (-4, -2), (-4, -3), (-4, -4), (-4, -5), (-4, -6), (-4, -7), (-4, -8), (-4, -9), (-3, -9), (-3, -8)], 'first_turn_left': True, 'is_trapped': False}
Episode 83199, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (-1, -2), (-1, -3), (0, -3), (1, -3), (2, -3), (2, -2), (3, -2), (3, -3), (4, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 83299, score: 3.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-2, 4), (-3, 4), (-4, 4), (-5, 4), (-6, 4), (-7, 4), (-7, 3), (-6, 3), (-5, 3), (-4, 3), (-3, 3), (-2, 3), (-1, 3), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 83399, score: 1.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (-1, 15), (-1, 14), (-1, 13), (-1, 12)], 'first_turn_left': True, 'is_trapped': False}
Episode 83499, score: 5.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-4, 1), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 83599, score: 6.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 1, 1, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (1, 3), (1, 4), (0, 4), (0, 5), (1, 5), (1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 83699, score: 3.0, epsilon: 0.03, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 83799, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 83899, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 83999, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (-1, 4), (-2, 4), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 84099, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (2, -1), (2, -2), (1, -2), (1, -3), (0, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 84199, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 0), (3, 0), (3, -1), (2, -1), (2, -2), (1, -2), (1, -3), (0, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 84299, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 0, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (7, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 84399, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 84499, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 84599, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 84699, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 13, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (1, -2), (1, -1), (0, -1), (0, 0)], 'first_turn_left': True, 'is_trapped': True}
Episode 84799, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (0, 4), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 84899, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 84999, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 85099, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, -2), (1, -2), (1, -3), (1, -4), (1, -5), (1, -6), (1, -7), (1, -8)], 'first_turn_left': True, 'is_trapped': False}
Episode 85199, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (2, 1), (2, 2), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 85299, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 85399, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 85499, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 1, 0, 0, 2, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-2, 2), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 85599, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9)], 'first_turn_left': True, 'is_trapped': False}
Episode 85699, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 85799, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 85899, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-4, 1), (-3, 1), (-3, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 85999, score: 1.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (-1, 16), (-1, 17), (0, 17)], 'first_turn_left': True, 'is_trapped': False}
Episode 86099, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 86199, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 86299, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (-1, 5), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 86399, score: 1.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 2, 0, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (-1, 7), (-1, 6), (-1, 5), (-2, 5), (-2, 6), (-3, 6), (-4, 6), (-5, 6), (-6, 6), (-6, 7), (-5, 7), (-5, 8)], 'first_turn_left': True, 'is_trapped': False}
Episode 86499, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (-1, 9), (-1, 8), (-1, 7), (-1, 6), (-1, 5), (-1, 4), (-2, 4), (-2, 3), (-1, 3), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 86599, score: 0.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19)], 'first_turn_left': False, 'is_trapped': False}
Episode 86699, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 2, 1, 1, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (-1, 5), (-2, 5), (-3, 5), (-3, 4), (-2, 4), (-1, 4), (-1, 3), (-2, 3), (-3, 3), (-4, 3), (-4, 4), (-5, 4), (-5, 5), (-4, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 86799, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 2, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (0, 3), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (2, 8), (2, 7), (2, 6), (2, 5), (2, 4), (2, 3), (2, 2), (2, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 86899, score: 0.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (-1, 13), (-1, 12), (-1, 11), (-1, 10), (-1, 9), (-2, 9)], 'first_turn_left': True, 'is_trapped': False}
Episode 86999, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 2, 1, 1, 1, 1, 1, 2, 2, 0, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (0, 3), (1, 3), (2, 3), (3, 3), (4, 3), (5, 3), (5, 2), (4, 2), (4, 1), (4, 0), (4, -1), (4, -2), (4, -3), (4, -4), (4, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 87099, score: 0.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (-1, 11), (-1, 12), (0, 12), (0, 13), (1, 13), (1, 12), (2, 12), (2, 11)], 'first_turn_left': True, 'is_trapped': False}
Episode 87199, score: 1.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (-1, 9), (-2, 9), (-3, 9), (-3, 8), (-2, 8), (-1, 8), (-1, 7), (-2, 7), (-2, 6), (-3, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 87299, score: 0.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (-1, 6), (-2, 6), (-3, 6), (-4, 6), (-5, 6), (-6, 6), (-7, 6), (-8, 6), (-9, 6), (-10, 6), (-11, 6), (-12, 6), (-13, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 87399, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (-1, 9), (-1, 8), (-1, 7), (-1, 6), (-1, 5), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 87499, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (-1, 8), (-1, 7), (-1, 6), (-1, 5), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 87599, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-3, 1), (-3, 0), (-2, 0), (-2, -1), (-2, -2), (-2, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 87699, score: 0.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (-1, 7), (-1, 8), (-2, 8), (-2, 7), (-2, 6), (-2, 5), (-3, 5), (-3, 6), (-3, 7), (-3, 8), (-3, 9), (-3, 10)], 'first_turn_left': True, 'is_trapped': False}
Episode 87799, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 0, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (-1, 5), (-1, 6), (0, 6), (0, 7), (-1, 7), (-2, 7), (-2, 6), (-2, 5), (-2, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 87899, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (-1, 3), (-2, 3), (-2, 2), (-2, 1), (-2, 0), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 87999, score: 0.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1, 1, 2, 1, 1, 1, 0, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-2, 4), (-3, 4), (-3, 5), (-2, 5), (-2, 6), (-3, 6), (-4, 6), (-5, 6), (-5, 7), (-5, 8), (-5, 9), (-5, 10), (-6, 10), (-7, 10)], 'first_turn_left': True, 'is_trapped': False}
Episode 88099, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (1, 4), (1, 3), (2, 3), (2, 2), (1, 2), (1, 1), (2, 1), (2, 0), (1, 0), (1, -1), (0, -1), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 88199, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (-1, 4), (-1, 5), (-1, 6), (-1, 7), (0, 7), (0, 6), (1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 88299, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 1, 1, 2, 2, 0, 1, 2, 1, 2, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-6, 1), (-6, 2), (-5, 2), (-5, 3), (-5, 4), (-4, 4), (-3, 4), (-3, 3), (-4, 3), (-4, 2), (-3, 2), (-2, 2), (-2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 88399, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (0, -6), (0, -5), (0, -4), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 88499, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 88599, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 88699, score: 1.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-6, 1), (-7, 1), (-8, 1), (-9, 1), (-10, 1), (-11, 1), (-12, 1), (-13, 1), (-14, 1), (-15, 1), (-15, 0), (-14, 0), (-13, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 88799, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (-1, -7), (-1, -8), (-1, -9), (-1, -10), (-1, -11), (-1, -12), (-1, -13), (-1, -14)], 'first_turn_left': True, 'is_trapped': False}
Episode 88899, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 2, 1, 2, 2, 0, 0, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-2, -3), (-3, -3), (-3, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, 1), (-3, 1), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 88999, score: 1.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (-1, 9), (-1, 10), (0, 10), (0, 11), (1, 11), (1, 10), (2, 10), (2, 9), (1, 9), (1, 8)], 'first_turn_left': True, 'is_trapped': False}
Episode 89099, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 89199, score: 1.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 2, 0, 0, 1, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-5, 1), (-5, 0), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 89299, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-4, 3), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 89399, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 89499, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 89599, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 89699, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 89799, score: 0.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 2, 0, 1, 0, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-4, 1), (-4, 0), (-4, -1), (-4, -2), (-3, -2), (-3, -1), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 89899, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (0, 2), (0, 3), (1, 3), (1, 2), (2, 2), (2, 1), (1, 1), (1, 0), (2, 0), (2, -1), (1, -1), (1, -2), (0, -2), (0, -1), (-1, -1), (-1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 89999, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 90099, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (2, -2), (2, -1), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 90199, score: 1.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 1.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 1, 2, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-3, 1), (-3, 2), (-2, 2), (-2, 3), (-3, 3), (-4, 3), (-4, 2), (-4, 1), (-4, 0), (-3, 0), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 90299, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-5, 2), (-5, 3), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 90399, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 90499, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (0, 4), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 90599, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-2, -1), (-2, -2), (-2, -3), (-2, -4), (-2, -5)], 'first_turn_left': True, 'is_trapped': False}
Episode 90699, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 0, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (0, -2), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 90799, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3), (-2, 4), (-1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 90899, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 90999, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 91099, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 91199, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 91299, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 91399, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 91499, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-4, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 91599, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 0, 0, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-1, 3), (0, 3), (0, 4), (-1, 4), (-2, 4), (-2, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 91699, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (0, 4), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 91799, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (0, 3), (1, 3), (1, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 91899, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 91999, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-4, 3), (-4, 2), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 92099, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 92199, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 92299, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (4, -1), (5, -1), (6, -1), (7, -1), (8, -1), (9, -1), (9, 0), (8, 0), (7, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 92399, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, -2), (0, -2), (0, -3), (-1, -3), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, 1)], 'first_turn_left': True, 'is_trapped': False}
Episode 92499, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 92599, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 92699, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 92799, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 92899, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 2, 0, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 4), (0, 4), (0, 5), (1, 5), (1, 6)], 'first_turn_left': True, 'is_trapped': False}
Episode 92999, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 93099, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 93199, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 2, 0, 0, 1, 2, 0, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-2, -2), (-2, -3), (-1, -3), (0, -3), (0, -4), (1, -4), (1, -3), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 93299, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 2, 2, 0, 2, 0, 0, 1, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, 0), (-4, 0), (-4, -1), (-4, -2), (-5, -2), (-5, -3), (-4, -3), (-3, -3), (-3, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 93399, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 93499, score: 3.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 3.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-2, -4), (-2, -5), (-2, -6), (-1, -6), (-1, -5), (-1, -4), (-1, -3), (-1, -2), (0, -2), (1, -2)], 'first_turn_left': True, 'is_trapped': False}
Episode 93599, score: 0.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 0.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-3, 0), (-4, 0), (-5, 0), (-6, 0), (-7, 0), (-8, 0), (-9, 0), (-10, 0), (-11, 0), (-12, 0), (-13, 0), (-14, 0), (-15, 0), (-16, 0), (-17, 0)], 'first_turn_left': True, 'is_trapped': False}
Episode 93699, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 1, 1, 2, 2, 1, 0, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-2, -3), (-2, -4), (-3, -4), (-3, -3), (-3, -2), (-4, -2), (-4, -1), (-5, -1), (-5, -2), (-5, -3), (-4, -3)], 'first_turn_left': True, 'is_trapped': False}
Episode 93799, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -3), (-4, -3), (-4, -2), (-5, -2), (-5, -1), (-4, -1), (-4, 0), (-5, 0), (-6, 0), (-6, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 93899, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 2, 0, 0, 1, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 93999, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 94099, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 94199, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 94299, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-3, 0), (-3, 1), (-4, 1), (-4, 0), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 94399, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 94499, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (2, 3), (3, 3), (3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 94599, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 94699, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-4, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 94799, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 1, 1, 0, 0, 1, 2, 1, 1, 1, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (2, -1), (3, -1), (3, 0), (2, 0), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (2, 4), (2, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 94899, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 94999, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 0, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-4, 3), (-4, 4), (-5, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 95099, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 95199, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 95299, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 95399, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 95499, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 0, 0, 2, 2, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3), (0, 3), (0, 2), (-1, 2), (-1, 3), (-1, 4), (0, 4), (0, 5)], 'first_turn_left': True, 'is_trapped': False}
Episode 95599, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 95699, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 95799, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 95899, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 95999, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 96099, score: 2.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0500, 1.0000, 0.0000],
        [0.0000, 0.1000, 1.0000, 0.0000]]), torch.Size([20, 4])), reward: 2.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (-1, 4), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (-1, -7), (-1, -8), (-1, -9), (-1, -10)], 'first_turn_left': True, 'is_trapped': False}
Episode 96199, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 1), (-3, 0), (-3, -1), (-2, -1)], 'first_turn_left': True, 'is_trapped': False}
Episode 96299, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 96399, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 96499, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 96599, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 96699, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 96799, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 96899, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 96999, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97099, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97199, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97299, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97399, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97499, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97599, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97699, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97799, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-4, 2), (-5, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 97899, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 97999, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98099, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98199, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98299, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98399, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98499, score: 6.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 6.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2), (-3, 3), (-2, 3), (-2, 4), (-3, 4)], 'first_turn_left': True, 'is_trapped': False}
Episode 98599, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98699, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98799, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98899, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 98999, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 99099, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 99199, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 99299, score: 5.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 5.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (2, 4), (1, 4), (1, 3), (0, 3), (0, 2), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 99399, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-1, -2), (0, -2), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}
Episode 99499, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 99599, score: 4.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 4.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 0, 0, 2, 1, 1, 1, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (2, 2), (2, 3), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8)], 'first_turn_left': True, 'is_trapped': False}
Episode 99699, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 99799, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 99899, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Episode 99999, score: 7.0, epsilon: 0.02, reward_max: 9.0
	s_prime: (tensor([[ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0500,  1.0000,  0.0000],
        [-0.0500,  0.0500,  1.0000,  0.0000]]), torch.Size([20, 4])), reward: 7.0, done: True, info: {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-1, 3), (-1, 4), (0, 4), (0, 3)], 'first_turn_left': True, 'is_trapped': False}
Complete
11532.584023714066
Best foldings:
[{'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 2, 2, 0, 0, 1, 2, 0, 2, 0, 1, 0, 0, 2, 0, 2, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-2, 0), (-2, 1), (-3, 1), (-3, 0), (-3, -1), (-4, -1), (-4, -2), (-5, -2), (-5, -3), (-5, -4), (-4, -4), (-4, -3), (-3, -3), (-3, -2), (-2, -2), (-1, -2)], 'first_turn_left': True, 'is_trapped': False}, {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 1, 2, 0, 0, 2, 2, 1, 1, 2, 1, 0, 0, 1], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (-1, -4), (-2, -4), (-2, -5), (-1, -5), (-1, -6), (-2, -6), (-3, -6), (-4, -6), (-4, -5), (-4, -4), (-5, -4), (-5, -5), (-5, -6)], 'first_turn_left': True, 'is_trapped': False}, {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 2, 2, 0, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 2, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, 0), (-3, 0), (-4, 0), (-5, 0), (-5, -1), (-4, -1), (-3, -1), (-3, -2), (-2, -2), (-2, -3), (-3, -3), (-4, -3), (-4, -2), (-5, -2)], 'first_turn_left': True, 'is_trapped': False}, {'chain_length': 20, 'seq_length': 20, 'actions': [0, 2, 0, 0, 1, 0, 2, 1, 2, 2, 0, 0, 1, 0, 1, 2, 0, 2], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 2), (-2, 2), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (-1, -2), (-2, -2), (-2, -1), (-3, -1), (-3, -2), (-3, -3), (-2, -3), (-1, -3), (-1, -4), (0, -4), (0, -5)], 'first_turn_left': True, 'is_trapped': False}, {'chain_length': 20, 'seq_length': 20, 'actions': [0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 2, 2, 1, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-1, 0), (-1, -1), (-1, -2), (-1, -3), (0, -3), (0, -4), (0, -5), (1, -5), (1, -4), (1, -3), (1, -2), (0, -2), (0, -1), (1, -1), (2, -1), (2, 0), (1, 0)], 'first_turn_left': True, 'is_trapped': False}, {'chain_length': 20, 'seq_length': 20, 'actions': [1, 1, 0, 0, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0, 1, 1, 0, 0], 'state': [(0, 0), (0, 1), (0, 2), (0, 3), (-1, 3), (-1, 2), (-1, 1), (-1, 0), (-1, -1), (-2, -1), (-2, -2), (-3, -2), (-3, -1), (-3, 0), (-2, 0), (-2, 1), (-2, 2), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}, {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (2, 1), (1, 1), (1, 2), (0, 2), (-1, 2), (-2, 2), (-2, 3), (-3, 3), (-3, 2)], 'first_turn_left': True, 'is_trapped': False}, {'chain_length': 20, 'seq_length': 20, 'actions': [0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 2, 0, 0], 'state': [(0, 0), (0, 1), (-1, 1), (-2, 1), (-2, 0), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (2, 0), (3, 0), (3, 1), (2, 1), (1, 1), (1, 2), (0, 2), (0, 3), (-1, 3), (-1, 2)], 'first_turn_left': True, 'is_trapped': False}]
